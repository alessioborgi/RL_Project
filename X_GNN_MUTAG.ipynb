{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2WbgJ3vqr0TE"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessioborgi/RL_Project/blob/main/X_GNN_MUTAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X-GNN: Model-Explanations of GNNs using RL\n",
        "\n",
        "### *Alessio Borgi*\n",
        "### *Francesco Danese*"
      ],
      "metadata": {
        "id": "JUUvLA8lri-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0: INSTALLING & IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "2WbgJ3vqr0TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric networkx matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE7aTsSLrdMk",
        "outputId": "ec3c65f8-47d7-437b-b3c4-9f35c905c1cf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import networkx as nx\n",
        "from torch.nn import Linear\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import plotly.graph_objects as go\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.utils import to_networkx, to_dense_adj\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops, degree"
      ],
      "metadata": {
        "id": "H6kL0ndKrzz3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensures that dataset splitting, model initialization, and training are deterministic.\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)  # Fix seed for PyTorch (CPU).\n",
        "    torch.cuda.manual_seed(seed)  # Fix seed for PyTorch (GPU).\n",
        "    torch.cuda.manual_seed_all(seed)  # Fix seed for all GPUs.\n",
        "    np.random.seed(seed)  # Fix seed for NumPy.\n",
        "    random.seed(seed)  # Fix seed for Python's random module.\n",
        "    torch.backends.cudnn.deterministic = True  # Ensure deterministic GPU behavior.\n",
        "    torch.backends.cudnn.benchmark = False  # Disable cuDNN auto-tuning to enforce determinism.\n",
        "\n",
        "set_seed(42)  # Set seed to ensure reproducibility across runs."
      ],
      "metadata": {
        "id": "FV3Oe3Ogr6Gi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1: DATASET EXPLORATION"
      ],
      "metadata": {
        "id": "tUwpo2PYr85a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MUTAG Dataset.\n",
        "dataset = TUDataset(root='data/TUDataset', name='MUTAG')"
      ],
      "metadata": {
        "id": "KoK2Qv1wr_G8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to collect dataset-wide statistics.\n",
        "num_nodes = []\n",
        "num_edges = []\n",
        "labels = []\n",
        "\n",
        "# Gather data about all graphs.\n",
        "for data in dataset:\n",
        "    num_nodes.append(data.num_nodes)\n",
        "    num_edges.append(data.num_edges)\n",
        "    labels.append(data.y.item())\n",
        "\n",
        "# Create a summary DataFrame.\n",
        "df = pd.DataFrame({\n",
        "    \"Graph ID\": range(len(dataset)),\n",
        "    \"Num Nodes\": num_nodes,\n",
        "    \"Num Edges\": num_edges,\n",
        "    \"Label\": labels\n",
        "})\n",
        "\n",
        "# Dataset Statistics.\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f\"Number of Graphs: {len(dataset)}\")\n",
        "print(f\"Number of Classes: {dataset.num_classes}\")\n",
        "print(f\"Average Nodes per Graph: {sum(num_nodes)/len(num_nodes):.2f}\")\n",
        "print(f\"Average Edges per Graph: {sum(num_edges)/len(num_edges):.2f}\")\n",
        "print(\"Class Distribution:\")\n",
        "print(df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjM6AWy2sBux",
        "outputId": "96c55e2e-b8e7-4af5-dc4c-6da49fcea59f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: MUTAG(188):\n",
            "====================\n",
            "Number of Graphs: 188\n",
            "Number of Classes: 2\n",
            "Average Nodes per Graph: 17.93\n",
            "Average Edges per Graph: 39.59\n",
            "Class Distribution:\n",
            "Label\n",
            "1    125\n",
            "0     63\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot class distribution using Plotly.\n",
        "class_counts = df['Label'].value_counts().reset_index()\n",
        "class_counts.columns = ['Label', 'Count']\n",
        "\n",
        "fig = px.bar(\n",
        "    class_counts,\n",
        "    x='Label', y='Count',\n",
        "    labels={\"Label\": \"Class Label\", \"Count\": \"Count\"},\n",
        "    title=\"Class Distribution in MUTAG Dataset\"\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fKGtzVSjsDoF",
        "outputId": "423edcab-db72-44b0-f6d7-87c1fa9e7edf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"0bc8bbac-55aa-40aa-aa63-e957b0ca183e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0bc8bbac-55aa-40aa-aa63-e957b0ca183e\")) {                    Plotly.newPlot(                        \"0bc8bbac-55aa-40aa-aa63-e957b0ca183e\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Class Label=%{x}\\u003cbr\\u003eCount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1,0],\"xaxis\":\"x\",\"y\":[125,63],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class Label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Class Distribution in MUTAG Dataset\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0bc8bbac-55aa-40aa-aa63-e957b0ca183e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the first graph of the Dataset.\n",
        "single_graph = dataset[0]\n",
        "print()\n",
        "print(single_graph)\n",
        "print('=============================================================')\n",
        "\n",
        "# Gather some statistics about the first graph.\n",
        "print(f'Number of nodes: {single_graph.num_nodes}')\n",
        "print(f'Number of edges: {single_graph.num_edges}')\n",
        "print(f'Average node degree: {single_graph.num_edges / single_graph.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {single_graph.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {single_graph.has_self_loops()}')\n",
        "print(f'Is undirected: {single_graph.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmgyk5Lhszvv",
        "outputId": "5b535b23-9298-4135-890d-4d4c79b9cb43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
            "=============================================================\n",
            "Number of nodes: 17\n",
            "Number of edges: 38\n",
            "Average node degree: 2.24\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import plotly.graph_objs as go\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you already have the graph data loaded as `single_graph`\n",
        "# Convert the first graph in the dataset to NetworkX.\n",
        "G = to_networkx(single_graph, to_undirected=True)\n",
        "\n",
        "# Extract the node feature matrix\n",
        "node_features = single_graph.x  # Shape: [num_nodes, num_features]\n",
        "\n",
        "# Convert one-hot encoded node features to atom types (indices)\n",
        "node_colors = torch.argmax(node_features, dim=1).numpy()\n",
        "\n",
        "# Define a colormap for different atom types\n",
        "cmap = plt.get_cmap(\"tab10\")  # You can choose any matplotlib colormap\n",
        "unique_atom_types = np.unique(node_colors)\n",
        "colors = {atom_type: cmap(i / len(unique_atom_types)) for i, atom_type in enumerate(unique_atom_types)}\n",
        "\n",
        "# Generate 2D layout\n",
        "pos_2d = nx.spring_layout(G, seed=42)\n",
        "\n",
        "# Prepare edge trace for 2D visualization\n",
        "edge_x_2d = []\n",
        "edge_y_2d = []\n",
        "for edge in G.edges():\n",
        "    x0, y0 = pos_2d[edge[0]]\n",
        "    x1, y1 = pos_2d[edge[1]]\n",
        "    edge_x_2d.extend([x0, x1, None])\n",
        "    edge_y_2d.extend([y0, y1, None])\n",
        "\n",
        "edge_trace_2d = go.Scatter(\n",
        "    x=edge_x_2d, y=edge_y_2d,\n",
        "    line=dict(width=0.5, color='#888'),\n",
        "    hoverinfo='none',\n",
        "    mode='lines'\n",
        ")\n",
        "\n",
        "# Prepare node trace for 2D visualization\n",
        "node_x_2d = []\n",
        "node_y_2d = []\n",
        "node_labels = []\n",
        "node_colors_plotly = []\n",
        "\n",
        "for node in G.nodes():\n",
        "    x, y = pos_2d[node]\n",
        "    node_x_2d.append(x)\n",
        "    node_y_2d.append(y)\n",
        "    atom_type_list = ['C', 'N', 'O', 'F', 'I', 'Cl', 'Br']\n",
        "    atom_type = atom_type_list[node_colors[node]]\n",
        "    node_labels.append(f\"{atom_type}\")\n",
        "    rgba_color = colors[node_colors[node]]\n",
        "    plotly_color = f\"rgba({rgba_color[0] * 255}, {rgba_color[1] * 255}, {rgba_color[2] * 255}, {rgba_color[3]})\"\n",
        "    node_colors_plotly.append(plotly_color)\n",
        "\n",
        "node_trace_2d = go.Scatter(\n",
        "    x=node_x_2d, y=node_y_2d,\n",
        "    mode='markers+text',\n",
        "    hoverinfo='text',\n",
        "    marker=dict(\n",
        "        size=10,\n",
        "        color=node_colors_plotly,\n",
        "    ),\n",
        "    text=node_labels,\n",
        "    textposition=\"top center\"\n",
        ")\n",
        "\n",
        "# 2D Visualization\n",
        "fig_2d = go.Figure(data=[edge_trace_2d, node_trace_2d],\n",
        "                   layout=go.Layout(\n",
        "                       title=\"2D Visualization of Graph 0\",\n",
        "                       showlegend=False,\n",
        "                       hovermode='closest',\n",
        "                       margin=dict(b=0, l=0, r=0, t=40),\n",
        "                       xaxis=dict(showgrid=False, zeroline=False),\n",
        "                       yaxis=dict(showgrid=False, zeroline=False)\n",
        "                   ))\n",
        "fig_2d.show()\n",
        "\n",
        "# Analyze graph properties\n",
        "print(f\"Number of nodes: {single_graph.num_nodes}\")\n",
        "print(f\"Number of edges: {single_graph.num_edges}\")\n",
        "print(f\"Is graph directed? {single_graph.is_directed()}\")\n",
        "print(f\"Graph label: {single_graph.y}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kf8xM0wOsFi7",
        "outputId": "f02070a0-58d4-4c16-fb6c-89dc0dd9bfcc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"12e44420-2514-4786-808a-7f497f48835d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"12e44420-2514-4786-808a-7f497f48835d\")) {                    Plotly.newPlot(                        \"12e44420-2514-4786-808a-7f497f48835d\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[-0.3727182492900634,-0.5510840196249834,null,-0.3727182492900634,-0.2299887901282408,null,-0.5510840196249834,-0.5438804985577245,null,-0.5438804985577245,-0.3766813157901222,null,-0.3766813157901222,-0.20885686146700344,null,-0.3766813157901222,-0.2665553478854011,null,-0.20885686146700344,-0.2299887901282408,null,-0.20885686146700344,-0.016589072446311765,null,-0.016589072446311765,0.04449844969654987,null,0.04449844969654987,-0.004549900306905611,null,-0.004549900306905611,-0.2665553478854011,null,-0.004549900306905611,0.17349067894459028,null,-0.2665553478854011,-0.20909489834523434,null,-0.20909489834523434,0.006577112790116703,null,0.006577112790116703,0.30487213864738016,null,0.30487213864738016,0.17349067894459028,null,0.30487213864738016,0.6260641640669481,null,0.6260641640669481,0.7958900025590367,null,0.6260641640669481,0.8286064071373688,null],\"y\":[1.0,0.8570191093083964,null,1.0,0.828528558137815,null,0.8570191093083964,0.5802363441080655,null,0.5802363441080655,0.30682370852924457,null,0.30682370852924457,0.5429957606160726,null,0.30682370852924457,-0.0705188995613755,null,0.5429957606160726,0.828528558137815,null,0.5429957606160726,0.3753641564577354,null,0.3753641564577354,0.12135433599050012,null,0.12135433599050012,-0.1484296524723047,null,-0.1484296524723047,-0.0705188995613755,null,-0.1484296524723047,-0.40582669457225157,null,-0.0705188995613755,-0.3993931571933171,null,-0.3993931571933171,-0.6191922903997025,null,-0.6191922903997025,-0.6515404053515196,null,-0.6515404053515196,-0.40582669457225157,null,-0.6515404053515196,-0.7588467657998171,null,-0.7588467657998171,-0.9358164791562336,null,-0.7588467657998171,-0.6227576286413062,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(214.0, 39.0, 40.0, 1.0)\",\"rgba(227.0, 119.0, 194.0, 1.0)\",\"rgba(227.0, 119.0, 194.0, 1.0)\"],\"size\":10},\"mode\":\"markers+text\",\"text\":[\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"N\",\"O\",\"O\"],\"textposition\":\"top center\",\"x\":[-0.3727182492900634,-0.5510840196249834,-0.5438804985577245,-0.3766813157901222,-0.20885686146700344,-0.2299887901282408,-0.016589072446311765,0.04449844969654987,-0.004549900306905611,-0.2665553478854011,-0.20909489834523434,0.006577112790116703,0.30487213864738016,0.17349067894459028,0.6260641640669481,0.7958900025590367,0.8286064071373688],\"y\":[1.0,0.8570191093083964,0.5802363441080655,0.30682370852924457,0.5429957606160726,0.828528558137815,0.3753641564577354,0.12135433599050012,-0.1484296524723047,-0.0705188995613755,-0.3993931571933171,-0.6191922903997025,-0.6515404053515196,-0.40582669457225157,-0.7588467657998171,-0.9358164791562336,-0.6227576286413062],\"type\":\"scatter\"}],                        {\"hovermode\":\"closest\",\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":40},\"showlegend\":false,\"title\":{\"text\":\"2D Visualization of Graph 0\"},\"xaxis\":{\"showgrid\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('12e44420-2514-4786-808a-7f497f48835d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 17\n",
            "Number of edges: 38\n",
            "Is graph directed? False\n",
            "Graph label: tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import plotly.graph_objs as go\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "single_graph = dataset[4]\n",
        "# Assuming you already have the graph data loaded as `single_graph`\n",
        "# Convert the first graph in the dataset to NetworkX.\n",
        "G = to_networkx(single_graph, to_undirected=True)\n",
        "\n",
        "# Extract the node feature matrix\n",
        "node_features = single_graph.x  # Shape: [num_nodes, num_features]\n",
        "\n",
        "# Convert one-hot encoded node features to atom types (indices)\n",
        "node_colors = torch.argmax(node_features, dim=1).numpy()\n",
        "\n",
        "# Define atom labels and fixed colormap\n",
        "atom_labels = ['C', 'N', 'O', 'F', 'I', 'Cl', 'Br']\n",
        "fixed_colors = {\n",
        "    'C': 'rgba(0, 255, 0, 1)',  # Green\n",
        "    'N': 'rgba(255, 0, 0, 1)',  # Red\n",
        "    'O': 'rgba(0, 0, 255, 1)',  # Blue\n",
        "    'F': 'rgba(255, 255, 0, 1)',  # Yellow\n",
        "    'I': 'rgba(128, 0, 128, 1)',  # Purple\n",
        "    'Cl': 'rgba(255, 165, 0, 1)',  # Orange\n",
        "    'Br': 'rgba(75, 0, 130, 1)'   # Indigo\n",
        "}\n",
        "\n",
        "# Generate 3D layout\n",
        "pos_3d = nx.spring_layout(G, dim=3, seed=42)\n",
        "\n",
        "# Extract node labels based on atom types\n",
        "node_labels = []\n",
        "node_colors_plotly = []\n",
        "for node in G.nodes():\n",
        "    atom_type = atom_labels[node_colors[node]]\n",
        "    node_labels.append(atom_type)\n",
        "    plotly_color = fixed_colors[atom_type]\n",
        "    node_colors_plotly.append(plotly_color)\n",
        "\n",
        "# Prepare edge trace for 3D visualization\n",
        "edge_x_3d = []\n",
        "edge_y_3d = []\n",
        "edge_z_3d = []\n",
        "for edge in G.edges():\n",
        "    x0, y0, z0 = pos_3d[edge[0]]\n",
        "    x1, y1, z1 = pos_3d[edge[1]]\n",
        "    edge_x_3d.extend([x0, x1, None])\n",
        "    edge_y_3d.extend([y0, y1, None])\n",
        "    edge_z_3d.extend([z0, z1, None])\n",
        "\n",
        "edge_trace_3d = go.Scatter3d(\n",
        "    x=edge_x_3d, y=edge_y_3d, z=edge_z_3d,\n",
        "    line=dict(width=0.5, color='#888'),\n",
        "    hoverinfo='none',\n",
        "    mode='lines'\n",
        ")\n",
        "\n",
        "# Prepare node trace for 3D visualization\n",
        "node_x_3d = []\n",
        "node_y_3d = []\n",
        "node_z_3d = []\n",
        "for node in G.nodes():\n",
        "    x, y, z = pos_3d[node]\n",
        "    node_x_3d.append(x)\n",
        "    node_y_3d.append(y)\n",
        "    node_z_3d.append(z)\n",
        "\n",
        "node_trace_3d = go.Scatter3d(\n",
        "    x=node_x_3d, y=node_y_3d, z=node_z_3d,\n",
        "    mode='markers+text',\n",
        "    hoverinfo='text',\n",
        "    marker=dict(\n",
        "        size=10,\n",
        "        color=node_colors_plotly,\n",
        "    ),\n",
        "    text=node_labels,\n",
        "    textposition=\"top center\"\n",
        ")\n",
        "\n",
        "# 3D Visualization\n",
        "fig_3d = go.Figure(data=[edge_trace_3d, node_trace_3d],\n",
        "                   layout=go.Layout(\n",
        "                       title=\"3D Visualization of Graph 0\",\n",
        "                       showlegend=False,\n",
        "                       margin=dict(b=0, l=0, r=0, t=40),\n",
        "                       scene=dict(\n",
        "                           xaxis=dict(showticklabels=False),\n",
        "                           yaxis=dict(showticklabels=False),\n",
        "                           zaxis=dict(showticklabels=False)\n",
        "                       )\n",
        "                   ))\n",
        "fig_3d.show()\n",
        "\n",
        "# Analyze graph properties\n",
        "print(f\"Number of nodes: {single_graph.num_nodes}\")\n",
        "print(f\"Number of edges: {single_graph.num_edges}\")\n",
        "print(f\"Is graph directed? {single_graph.is_directed()}\")\n",
        "print(f\"Graph label: {single_graph.y}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8dRhlu6ZsP6R",
        "outputId": "e1139321-5603-4379-95c8-a0c2c0f3d0db"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"a4742b53-d229-483e-bb0e-a0727e62fe64\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a4742b53-d229-483e-bb0e-a0727e62fe64\")) {                    Plotly.newPlot(                        \"a4742b53-d229-483e-bb0e-a0727e62fe64\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[0.02458546069025762,-0.2497724533846732,null,0.02458546069025762,0.3506783398707835,null,-0.2497724533846732,-0.33870899413810185,null,-0.33870899413810185,-0.007160738692036449,null,-0.33870899413810185,-0.6893228619804218,null,-0.007160738692036449,0.2481327865347945,null,-0.007160738692036449,0.018497996295593084,null,0.2481327865347945,0.3506783398707835,null,0.3506783398707835,0.5873156864975905,null,0.018497996295593084,-0.08369490102825228,null,0.018497996295593084,0.13944967933446725,null],\"y\":[-0.13351455396521839,-0.050148520252982914,null,-0.13351455396521839,-0.1888365195744066,null,-0.050148520252982914,0.0059437570218711195,null,0.0059437570218711195,0.048923917773303786,null,0.0059437570218711195,-0.010695959720479414,null,0.048923917773303786,-0.0775316434784458,null,0.048923917773303786,0.183619246357252,null,-0.0775316434784458,-0.1888365195744066,null,-0.1888365195744066,-0.3092693102440526,null,0.183619246357252,0.40499888411238844,null,0.183619246357252,0.12651070197077038,null],\"z\":[0.6640739399357102,0.45847939511230384,null,0.6640739399357102,0.5594011291999086,null,0.45847939511230384,0.0871366963812924,null,0.0871366963812924,-0.1966109723140789,null,0.0871366963812924,0.07226906111168803,null,-0.1966109723140789,0.1586094094460366,null,-0.1966109723140789,-0.6772928364646472,null,0.1586094094460366,0.5594011291999086,null,0.5594011291999086,0.8034406719279515,null,-0.6772928364646472,-0.9295064943361648,null,-0.6772928364646472,-1.0,null],\"type\":\"scatter3d\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(255, 255, 0, 1)\",\"rgba(255, 0, 0, 1)\",\"rgba(0, 0, 255, 1)\",\"rgba(0, 0, 255, 1)\",\"rgba(255, 255, 0, 1)\"],\"size\":10},\"mode\":\"markers+text\",\"text\":[\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"F\",\"N\",\"O\",\"O\",\"F\"],\"textposition\":\"top center\",\"x\":[0.02458546069025762,-0.2497724533846732,-0.33870899413810185,-0.007160738692036449,0.2481327865347945,0.3506783398707835,0.5873156864975905,0.018497996295593084,-0.08369490102825228,0.13944967933446725,-0.6893228619804218],\"y\":[-0.13351455396521839,-0.050148520252982914,0.0059437570218711195,0.048923917773303786,-0.0775316434784458,-0.1888365195744066,-0.3092693102440526,0.183619246357252,0.40499888411238844,0.12651070197077038,-0.010695959720479414],\"z\":[0.6640739399357102,0.45847939511230384,0.0871366963812924,-0.1966109723140789,0.1586094094460366,0.5594011291999086,0.8034406719279515,-0.6772928364646472,-0.9295064943361648,-1.0,0.07226906111168803],\"type\":\"scatter3d\"}],                        {\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":40},\"scene\":{\"xaxis\":{\"showticklabels\":false},\"yaxis\":{\"showticklabels\":false},\"zaxis\":{\"showticklabels\":false}},\"showlegend\":false,\"title\":{\"text\":\"3D Visualization of Graph 0\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a4742b53-d229-483e-bb0e-a0727e62fe64');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 11\n",
            "Number of edges: 22\n",
            "Is graph directed? False\n",
            "Graph label: tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for d in dataset:\n",
        "  if d.x[:, 4].sum().item() > 0:\n",
        "    print(i)\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ojHYP6z7XqZ",
        "outputId": "4f7fcb7a-ccd9-4d64-a849-b523f12882ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle()\n",
        "\n",
        "train_dataset = dataset[:150]\n",
        "test_dataset = dataset[150:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj6g8d1YsXOO",
        "outputId": "a2b8b696-0ca7-44cb-d6ab-99855ff737da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training graphs: 150\n",
            "Number of test graphs: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PARTE DEL CINESE\n"
      ],
      "metadata": {
        "id": "DsjhJdjdpibq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "\n",
        "# MUTAG dataset features: 188 graphs, totaling 3371 nodes, 7442 edges, represented as an undirected graph\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def load_split_MUTAG_data(path=\"/content/datas/\", dataset=\"MUTAG_\", split_train=0.7, split_val=0.15):\n",
        "    \"\"\"Load MUTAG data\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    # Load graph labels\n",
        "    graph_labels = np.genfromtxt(\"{}{}graph_labels.txt\".format(path, dataset),\n",
        "                                 dtype=np.dtype(int))\n",
        "    graph_labels = encode_onehot(graph_labels)  # (188, 2)\n",
        "    graph_labels = torch.LongTensor(np.where(graph_labels)[1])  # (188, 1)\n",
        "\n",
        "    # Graph node indices\n",
        "    graph_idx = np.genfromtxt(\"{}{}graph_indicator.txt\".format(path, dataset),\n",
        "                              dtype=np.dtype(int))\n",
        "\n",
        "    graph_idx = np.array(graph_idx, dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(graph_idx)}  # key, value indicates the starting node index of the graph key is value\n",
        "    length = len(idx_map.keys())  # Total number of graphs\n",
        "    num_nodes = [idx_map[n] - idx_map[n - 1] if n - 1 > 1 else idx_map[n] for n in range(1, length + 1)]  # A list of length 188 representing the number of nodes in each graph\n",
        "    max_num_nodes = max(num_nodes)  # Maximum number of nodes in a single graph\n",
        "    features_list = []\n",
        "    adj_list = []\n",
        "    prev = 0\n",
        "\n",
        "    # Node labels\n",
        "    nodeidx_features = np.genfromtxt(\"{}{}node_labels.txt\".format(path, dataset), delimiter=\",\",\n",
        "                                     dtype=np.dtype(int))\n",
        "    node_features = np.zeros((nodeidx_features.shape[0], max(nodeidx_features) + 1))\n",
        "    node_features[np.arange(nodeidx_features.shape[0]), nodeidx_features] = 1\n",
        "\n",
        "    # Edge information\n",
        "    edges_unordered = np.genfromtxt(\"{}{}A.txt\".format(path, dataset), delimiter=\",\",\n",
        "                                    dtype=np.int32)\n",
        "\n",
        "    # Edge labels\n",
        "    edges_label = np.genfromtxt(\"{}{}edge_labels.txt\".format(path, dataset), delimiter=\",\",\n",
        "                                dtype=np.int32)  # shape = (7442,)\n",
        "\n",
        "    # Generate adjacency matrix A, which includes all edges in the dataset\n",
        "    adj = sp.coo_matrix((edges_label, (edges_unordered[:, 0] - 1, edges_unordered[:, 1] - 1)))\n",
        "\n",
        "    # Formula in the paper: A^ = (D~)^0.5 A~ (D~)^0.5\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    node_features = normalize(node_features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))  # Corresponds to the formula A~ = A + IN\n",
        "    adj = adj.todense()\n",
        "\n",
        "    for n in range(1, length + 1):\n",
        "        # 'entry' is the feature matrix X for the n-th graph\n",
        "        entry = np.zeros((max_num_nodes, max(nodeidx_features) + 1))\n",
        "        entry[:idx_map[n] - prev] = node_features[prev:idx_map[n]]\n",
        "        entry = torch.FloatTensor(entry)\n",
        "        features_list.append(entry.tolist())\n",
        "\n",
        "        # 'entry' is the adjacency matrix A for the n-th graph\n",
        "        entry = np.zeros((max_num_nodes, max_num_nodes))\n",
        "        entry[:idx_map[n] - prev, :idx_map[n] - prev] = adj[prev:idx_map[n], prev:idx_map[n]]\n",
        "        entry = torch.FloatTensor(entry)\n",
        "        adj_list.append(entry.tolist())\n",
        "\n",
        "        prev = idx_map[n]  # 'prev' is the starting node index for the next graph\n",
        "\n",
        "    num_total = max(graph_idx)\n",
        "    num_train = int(split_train * num_total)\n",
        "    num_val = int((split_train + split_val) * num_total)\n",
        "\n",
        "    if (num_train == num_val or num_val == num_total):\n",
        "        return\n",
        "\n",
        "    features_list = torch.FloatTensor(features_list)\n",
        "    adj_list = torch.FloatTensor(adj_list)\n",
        "\n",
        "    idx_train = range(num_train)\n",
        "    idx_val = range(num_train, num_val)\n",
        "    idx_test = range(num_val, num_total)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    # Return values in order: adjacency matrices list of 188 graphs, feature matrices list of 188 graphs, labels of 188 graphs, starting node index of each graph, training set indices, validation set indices, test set indices\n",
        "    return adj_list, features_list, graph_labels, idx_map, idx_train, idx_val, idx_test\n"
      ],
      "metadata": {
        "id": "OMFErq4cpnKd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GNN MODEL"
      ],
      "metadata": {
        "id": "ztZVpElEp1NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model to Explain (GCN)\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "class GraphConvolution(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    paper: Semi-Supervised Classification with Graph Convolutional Networks\n",
        "    \"\"\"\n",
        "    # The parameters of the model include weight and bias\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))  # Weight matrix for the GCN layer\n",
        "        self.bias = Parameter(torch.FloatTensor(out_features))  # Bias term for the GCN layer\n",
        "        self.reset_parameters()  # Initialize parameters\n",
        "\n",
        "    # Weight initialization\n",
        "    def reset_parameters(self):\n",
        "        # Initialize weights and biases using uniform distribution based on the size of the output features\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    # Representation function, similar to __str__\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "    # Compute A~ X W(0), where A~ is the normalized adjacency matrix and X is the input feature matrix\n",
        "    def forward(self, input, adj):\n",
        "        # input.shape = [num_nodes, features] = X\n",
        "        # adj.shape = [num_nodes, num_nodes] = A~\n",
        "        # torch.mm(a, b) performs matrix multiplication of a and b, torch.mul(a, b) performs element-wise multiplication (a and b must have the same dimensions)\n",
        "        support = torch.mm(input, self.weight)  # Matrix multiplication of input features with weights, shape = [max_node, out_features]\n",
        "        output = torch.spmm(adj, support)  # Multiply normalized adjacency matrix with the support matrix, shape = [max_node, out_features]\n",
        "        return output + self.bias  # Add bias term, shape = [max_node, out_features]\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    # nfeat: number of input features, nclass: number of classes for classification, dropout: dropout rate\n",
        "    def __init__(self, nfeat, nclass, dropout):\n",
        "        \"\"\" As per paper \"\"\"\n",
        "        \"\"\" 3 layers of GCNs with output dimensions equal to 32, 48, 64 respectively and average all node features \"\"\"\n",
        "        \"\"\" Final classifier with 2 fully connected layers and hidden dimension set to 32 \"\"\"\n",
        "        \"\"\" Activation function - ReLu (Mutag) \"\"\"\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define three GCN layers with increasing output dimensions\n",
        "        self.gc1 = GraphConvolution(nfeat, 32)  # First GCN layer (input features -> 32)\n",
        "        self.gc2 = GraphConvolution(32, 48)  # Second GCN layer (32 -> 48)\n",
        "        self.gc3 = GraphConvolution(48, 64)  # Third GCN layer (48 -> 64)\n",
        "\n",
        "        # Define two fully connected (linear) layers for classification\n",
        "        self.fc1 = nn.Linear(64, 32)  # First fully connected layer (64 -> 32)\n",
        "        self.fc2 = nn.Linear(32, nclass)  # Second fully connected layer (32 -> nclass)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x.shape = [max_node, features]\n",
        "        # adj.shape = [max_node, max_node]\n",
        "\n",
        "        # First GCN layer with ReLU activation and dropout\n",
        "        x = F.relu(self.gc1(x, adj))  # x.shape = [num_nodes, 32]\n",
        "        x = F.dropout(x, self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Second GCN layer with ReLU activation and dropout\n",
        "        x = F.relu(self.gc2(x, adj))  # x.shape = [num_nodes, 48]\n",
        "        x = F.dropout(x, self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Third GCN layer with ReLU activation\n",
        "        x = F.relu(self.gc3(x, adj))  # x.shape = [num_nodes, 64]\n",
        "\n",
        "        # Aggregate all node features by taking the mean of all nodes\n",
        "        y = torch.mean(x, 0)  # y.shape = [64], aggregate using mean over all nodes\n",
        "\n",
        "        # Apply fully connected layers for final classification\n",
        "        y = F.relu(self.fc1(y))  # First fully connected layer with ReLU activation, y.shape = [32]\n",
        "        y = F.dropout(y, self.dropout, training=self.training)  # Apply dropout\n",
        "        y = F.softmax(self.fc2(y), dim=0)  # Second fully connected layer with softmax activation, y.shape = [nclass]\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Random input features of 29 nodes, each with 7 features\n",
        "    input = torch.rand(29, 7)\n",
        "    # Random adjacency matrix of size 29x29\n",
        "    adj = torch.rand(29, 29)\n",
        "\n",
        "    # Initialize the GCN model with 7 input features, 2 output classes, and a dropout rate of 0.1\n",
        "    model = GCN(nfeat=7,  # nfeat = 7\n",
        "                nclass=2,  # nclass = 2\n",
        "                dropout=0.1)\n",
        "\n",
        "    # Forward pass through the model\n",
        "    output = model(input, adj)\n",
        "    print(output.size())  # Output size should be [nclass], which is [2] in this case\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGQ-uM_kp2qX",
        "outputId": "78d56b5c-3f93-444f-e772-c3138cf90d3e",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset reshaping for training\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def load_dataset_and_split(train_percent=0.8):\n",
        "    # Prepare the output tensors\n",
        "    num_graphs = len(dataset)\n",
        "    max_nodes = 29  # Given that 29 is the maximum number of nodes in a single graph\n",
        "    num_features = 7\n",
        "\n",
        "    # Initialize the lists to hold the reshaped data\n",
        "    adj_list = torch.zeros((num_graphs, max_nodes, max_nodes))  # [188, 29, 29]\n",
        "    features_list = torch.zeros((num_graphs, max_nodes, num_features))  # [188, 29, 7]\n",
        "    graph_labels = torch.zeros(num_graphs, dtype=torch.long)  # [188]\n",
        "\n",
        "    # Iterate over each graph in the dataset\n",
        "    for i, data in enumerate(dataset):\n",
        "        # Number of nodes in the current graph\n",
        "        num_nodes = data.num_nodes\n",
        "\n",
        "        # Extract the node feature matrix x and store it in features_list\n",
        "        features = data.x  # Shape: [num_nodes, num_features]\n",
        "        features_list[i, :num_nodes, :] = features  # Padding remaining nodes with zeros\n",
        "\n",
        "        # Create adjacency matrix from edge index and add self-loops\n",
        "        adj = to_dense_adj(data.edge_index, max_num_nodes=max_nodes)[0]  # Convert edge index to dense adjacency matrix\n",
        "        adj = adj + torch.eye(max_nodes)  # Add self-loops by adding an identity matrix\n",
        "        adj_list[i] = adj\n",
        "\n",
        "        # Store the graph label\n",
        "        graph_labels[i] = data.y\n",
        "\n",
        "    # Create train-val-test split indices\n",
        "    num_train = int(train_percent * num_graphs)  # 80% of the data for training\n",
        "    num_val = num_graphs - num_train\n",
        "\n",
        "    # Generate shuffled indices\n",
        "    indices = torch.randperm(num_graphs)\n",
        "\n",
        "    # Assign indices to each split\n",
        "    idx_train = indices[:num_train]\n",
        "    idx_val = indices[num_train:]\n",
        "\n",
        "    # Print the shapes to confirm\n",
        "    print('adj_list:', adj_list.shape)  # Should be [188, 29, 29]\n",
        "    print('features_list:', features_list.shape)  # Should be [188, 29, 7]\n",
        "    print('graph_labels:', graph_labels.shape)  # Should be [188]\n",
        "    print('idx_train:', idx_train.shape)  # Should be [80% of 188]\n",
        "    print('idx_val:', idx_val.shape)  # Should be [20% of 188]\n",
        "\n",
        "    return adj_list, features_list, graph_labels, idx_train, idx_val"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aZGaCZEIbeZ8"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training the GCN\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_path = 'model/gcn_first.pth'\n",
        "\n",
        "epochs = 100\n",
        "lr = 0.001\n",
        "dropout = 0.1\n",
        "weight_decay = 5e-4\n",
        "\n",
        "class EarlyStopping():\n",
        "    def __init__(self, patience=10, min_loss=0.5, hit_min_before_stopping=False):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.hit_min_before_stopping = hit_min_before_stopping\n",
        "        if hit_min_before_stopping:\n",
        "            self.min_loss = min_loss\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = loss\n",
        "        elif loss > self.best_loss:\n",
        "            self.counter += 1\n",
        "            if self.counter > self.patience:\n",
        "                if self.hit_min_before_stopping == True and loss > self.min_loss:\n",
        "                    print(\"Cannot hit min loss, will continue\")\n",
        "                    self.counter -= self.patience\n",
        "                else:\n",
        "                    self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = loss\n",
        "            counter = 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # adj_list: [188, 29, 29]\n",
        "    # features_list: [188, 29, 7]\n",
        "    # graph_labels: [188]\n",
        "    adj_list, features_list, graph_labels, idx_train, idx_val = load_dataset_and_split()\n",
        "\n",
        "    model = GCN(nfeat=features_list[0].shape[1], # nfeat = 7\n",
        "                nclass=graph_labels.max().item() + 1, # nclass = 2\n",
        "                dropout=dropout)\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    model.cuda()\n",
        "    features_list = features_list.cuda()\n",
        "    adj_list = adj_list.cuda()\n",
        "    graph_labels = graph_labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "\n",
        "    early_stopping = EarlyStopping(patience=20, hit_min_before_stopping=True)\n",
        "    t_total = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # # Forward pass through entire training set\n",
        "        outputs = []\n",
        "        outputs = [model(features_list[i], adj_list[i]).unsqueeze(0) for i in idx_train]\n",
        "        output = torch.cat(outputs, dim=0)\n",
        "\n",
        "        loss_train = F.nll_loss(torch.log(output), graph_labels[idx_train])\n",
        "        acc_train = accuracy(output, graph_labels[idx_train])\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        # # Forward pass through entire validation set\n",
        "        outputs = []\n",
        "        outputs = [model(features_list[i], adj_list[i]).unsqueeze(0) for i in idx_val]\n",
        "        output = torch.cat(outputs, dim=0)\n",
        "        loss_val = F.nll_loss(torch.log(output), graph_labels[idx_val])\n",
        "        acc_val = accuracy(output, graph_labels[idx_val])\n",
        "\n",
        "        print('Epoch: {:04d}'.format(epoch + 1),\n",
        "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "        early_stopping(loss_val)\n",
        "        if early_stopping.early_stop == True:\n",
        "            break\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9591j-ct0L2",
        "outputId": "a95a033d-710b-4684-a4e5-b91bd7a440fb",
        "cellView": "form"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj_list: torch.Size([188, 29, 29])\n",
            "features_list: torch.Size([188, 29, 7])\n",
            "graph_labels: torch.Size([188])\n",
            "idx_train: torch.Size([150])\n",
            "idx_val: torch.Size([38])\n",
            "Epoch: 0001 loss_train: 0.6680 acc_train: 0.6400 loss_val: 0.6271 acc_val: 0.7632 time: 0.8335s\n",
            "Epoch: 0002 loss_train: 0.6592 acc_train: 0.6400 loss_val: 0.6152 acc_val: 0.7632 time: 0.3909s\n",
            "Epoch: 0003 loss_train: 0.6508 acc_train: 0.6400 loss_val: 0.6060 acc_val: 0.7632 time: 0.5709s\n",
            "Epoch: 0004 loss_train: 0.6439 acc_train: 0.6400 loss_val: 0.5981 acc_val: 0.7632 time: 0.4906s\n",
            "Epoch: 0005 loss_train: 0.6398 acc_train: 0.6400 loss_val: 0.5901 acc_val: 0.7632 time: 0.5570s\n",
            "Epoch: 0006 loss_train: 0.6346 acc_train: 0.6400 loss_val: 0.5814 acc_val: 0.7632 time: 0.4102s\n",
            "Epoch: 0007 loss_train: 0.6306 acc_train: 0.6400 loss_val: 0.5723 acc_val: 0.7632 time: 0.5351s\n",
            "Epoch: 0008 loss_train: 0.6244 acc_train: 0.6400 loss_val: 0.5628 acc_val: 0.7632 time: 0.3826s\n",
            "Epoch: 0009 loss_train: 0.6202 acc_train: 0.6400 loss_val: 0.5530 acc_val: 0.7632 time: 0.5243s\n",
            "Epoch: 0010 loss_train: 0.6111 acc_train: 0.6400 loss_val: 0.5431 acc_val: 0.7632 time: 0.4712s\n",
            "Epoch: 0011 loss_train: 0.6127 acc_train: 0.6400 loss_val: 0.5326 acc_val: 0.7632 time: 0.6916s\n",
            "Epoch: 0012 loss_train: 0.6049 acc_train: 0.6400 loss_val: 0.5222 acc_val: 0.7632 time: 0.5413s\n",
            "Epoch: 0013 loss_train: 0.6025 acc_train: 0.6400 loss_val: 0.5121 acc_val: 0.7632 time: 0.3552s\n",
            "Epoch: 0014 loss_train: 0.5996 acc_train: 0.6400 loss_val: 0.5027 acc_val: 0.7632 time: 0.5229s\n",
            "Epoch: 0015 loss_train: 0.5929 acc_train: 0.6400 loss_val: 0.4940 acc_val: 0.7632 time: 1.0412s\n",
            "Epoch: 0016 loss_train: 0.5964 acc_train: 0.6400 loss_val: 0.4865 acc_val: 0.7632 time: 0.8557s\n",
            "Epoch: 0017 loss_train: 0.5931 acc_train: 0.6400 loss_val: 0.4801 acc_val: 0.7632 time: 0.7769s\n",
            "Epoch: 0018 loss_train: 0.5914 acc_train: 0.6400 loss_val: 0.4749 acc_val: 0.7632 time: 0.8053s\n",
            "Epoch: 0019 loss_train: 0.5872 acc_train: 0.6400 loss_val: 0.4709 acc_val: 0.7632 time: 0.4334s\n",
            "Epoch: 0020 loss_train: 0.5946 acc_train: 0.6400 loss_val: 0.4681 acc_val: 0.7632 time: 0.4477s\n",
            "Epoch: 0021 loss_train: 0.5871 acc_train: 0.6400 loss_val: 0.4663 acc_val: 0.7632 time: 0.4712s\n",
            "Epoch: 0022 loss_train: 0.5887 acc_train: 0.6400 loss_val: 0.4652 acc_val: 0.7632 time: 0.3767s\n",
            "Epoch: 0023 loss_train: 0.5825 acc_train: 0.6400 loss_val: 0.4648 acc_val: 0.7632 time: 0.4024s\n",
            "Epoch: 0024 loss_train: 0.5852 acc_train: 0.6400 loss_val: 0.4652 acc_val: 0.7632 time: 0.4030s\n",
            "Epoch: 0025 loss_train: 0.5790 acc_train: 0.6400 loss_val: 0.4660 acc_val: 0.7632 time: 0.3788s\n",
            "Epoch: 0026 loss_train: 0.5791 acc_train: 0.6400 loss_val: 0.4675 acc_val: 0.7632 time: 0.4889s\n",
            "Epoch: 0027 loss_train: 0.5688 acc_train: 0.6400 loss_val: 0.4690 acc_val: 0.7632 time: 0.3590s\n",
            "Epoch: 0028 loss_train: 0.5698 acc_train: 0.6400 loss_val: 0.4705 acc_val: 0.7632 time: 0.3653s\n",
            "Epoch: 0029 loss_train: 0.5703 acc_train: 0.6400 loss_val: 0.4716 acc_val: 0.7632 time: 0.6683s\n",
            "Epoch: 0030 loss_train: 0.5728 acc_train: 0.6400 loss_val: 0.4722 acc_val: 0.7632 time: 0.7934s\n",
            "Epoch: 0031 loss_train: 0.5676 acc_train: 0.6400 loss_val: 0.4719 acc_val: 0.7632 time: 0.4262s\n",
            "Epoch: 0032 loss_train: 0.5655 acc_train: 0.6400 loss_val: 0.4708 acc_val: 0.7632 time: 0.6937s\n",
            "Epoch: 0033 loss_train: 0.5685 acc_train: 0.6400 loss_val: 0.4687 acc_val: 0.7632 time: 0.6421s\n",
            "Epoch: 0034 loss_train: 0.5579 acc_train: 0.6400 loss_val: 0.4654 acc_val: 0.7632 time: 0.6969s\n",
            "Epoch: 0035 loss_train: 0.5561 acc_train: 0.6400 loss_val: 0.4606 acc_val: 0.7632 time: 0.5888s\n",
            "Epoch: 0036 loss_train: 0.5553 acc_train: 0.6400 loss_val: 0.4549 acc_val: 0.7632 time: 0.5447s\n",
            "Epoch: 0037 loss_train: 0.5484 acc_train: 0.6400 loss_val: 0.4491 acc_val: 0.7632 time: 0.9008s\n",
            "Epoch: 0038 loss_train: 0.5532 acc_train: 0.6400 loss_val: 0.4436 acc_val: 0.7632 time: 1.0684s\n",
            "Epoch: 0039 loss_train: 0.5501 acc_train: 0.6400 loss_val: 0.4389 acc_val: 0.7632 time: 0.8929s\n",
            "Epoch: 0040 loss_train: 0.5472 acc_train: 0.6400 loss_val: 0.4348 acc_val: 0.7632 time: 0.8758s\n",
            "Epoch: 0041 loss_train: 0.5385 acc_train: 0.6400 loss_val: 0.4313 acc_val: 0.7632 time: 0.6866s\n",
            "Epoch: 0042 loss_train: 0.5326 acc_train: 0.6400 loss_val: 0.4281 acc_val: 0.7632 time: 0.3106s\n",
            "Epoch: 0043 loss_train: 0.5360 acc_train: 0.6400 loss_val: 0.4255 acc_val: 0.7632 time: 0.2173s\n",
            "Epoch: 0044 loss_train: 0.5275 acc_train: 0.6400 loss_val: 0.4228 acc_val: 0.7632 time: 0.2171s\n",
            "Epoch: 0045 loss_train: 0.5212 acc_train: 0.6400 loss_val: 0.4190 acc_val: 0.7632 time: 0.2357s\n",
            "Epoch: 0046 loss_train: 0.5296 acc_train: 0.6400 loss_val: 0.4145 acc_val: 0.7632 time: 0.2317s\n",
            "Epoch: 0047 loss_train: 0.5185 acc_train: 0.6467 loss_val: 0.4093 acc_val: 0.7632 time: 0.2163s\n",
            "Epoch: 0048 loss_train: 0.5155 acc_train: 0.6533 loss_val: 0.4034 acc_val: 0.7632 time: 0.2138s\n",
            "Epoch: 0049 loss_train: 0.5097 acc_train: 0.6600 loss_val: 0.3979 acc_val: 0.7632 time: 0.2286s\n",
            "Epoch: 0050 loss_train: 0.5085 acc_train: 0.6467 loss_val: 0.3927 acc_val: 0.7632 time: 0.2315s\n",
            "Epoch: 0051 loss_train: 0.5017 acc_train: 0.6600 loss_val: 0.3867 acc_val: 0.7368 time: 0.2287s\n",
            "Epoch: 0052 loss_train: 0.4916 acc_train: 0.7000 loss_val: 0.3793 acc_val: 0.7895 time: 0.2131s\n",
            "Epoch: 0053 loss_train: 0.4925 acc_train: 0.6933 loss_val: 0.3725 acc_val: 0.7895 time: 0.2171s\n",
            "Epoch: 0054 loss_train: 0.4906 acc_train: 0.7333 loss_val: 0.3682 acc_val: 0.7895 time: 0.2289s\n",
            "Epoch: 0055 loss_train: 0.4875 acc_train: 0.7400 loss_val: 0.3642 acc_val: 0.8158 time: 0.2349s\n",
            "Epoch: 0056 loss_train: 0.4855 acc_train: 0.7533 loss_val: 0.3596 acc_val: 0.8158 time: 0.2176s\n",
            "Epoch: 0057 loss_train: 0.4794 acc_train: 0.7533 loss_val: 0.3537 acc_val: 0.8684 time: 0.2409s\n",
            "Epoch: 0058 loss_train: 0.4768 acc_train: 0.7533 loss_val: 0.3479 acc_val: 0.8947 time: 0.2409s\n",
            "Epoch: 0059 loss_train: 0.4723 acc_train: 0.7600 loss_val: 0.3409 acc_val: 0.8947 time: 0.2341s\n",
            "Epoch: 0060 loss_train: 0.4628 acc_train: 0.7667 loss_val: 0.3349 acc_val: 0.8947 time: 0.2248s\n",
            "Epoch: 0061 loss_train: 0.4587 acc_train: 0.8000 loss_val: 0.3308 acc_val: 0.8947 time: 0.2162s\n",
            "Epoch: 0062 loss_train: 0.4621 acc_train: 0.7800 loss_val: 0.3261 acc_val: 0.8947 time: 0.2265s\n",
            "Epoch: 0063 loss_train: 0.4700 acc_train: 0.7667 loss_val: 0.3338 acc_val: 0.9211 time: 0.2231s\n",
            "Epoch: 0064 loss_train: 0.4682 acc_train: 0.7600 loss_val: 0.3412 acc_val: 0.8684 time: 0.2408s\n",
            "Epoch: 0065 loss_train: 0.4596 acc_train: 0.7800 loss_val: 0.3280 acc_val: 0.9211 time: 0.2382s\n",
            "Epoch: 0066 loss_train: 0.4476 acc_train: 0.7667 loss_val: 0.3168 acc_val: 0.9211 time: 0.2414s\n",
            "Epoch: 0067 loss_train: 0.4503 acc_train: 0.7867 loss_val: 0.3099 acc_val: 0.8947 time: 0.2220s\n",
            "Epoch: 0068 loss_train: 0.4420 acc_train: 0.8000 loss_val: 0.3105 acc_val: 0.9211 time: 0.2361s\n",
            "Epoch: 0069 loss_train: 0.4409 acc_train: 0.7600 loss_val: 0.3152 acc_val: 0.8947 time: 0.2188s\n",
            "Epoch: 0070 loss_train: 0.4502 acc_train: 0.8000 loss_val: 0.3226 acc_val: 0.8684 time: 0.2255s\n",
            "Epoch: 0071 loss_train: 0.4480 acc_train: 0.7933 loss_val: 0.3210 acc_val: 0.8947 time: 0.2253s\n",
            "Epoch: 0072 loss_train: 0.4409 acc_train: 0.8000 loss_val: 0.3095 acc_val: 0.8947 time: 0.2227s\n",
            "Epoch: 0073 loss_train: 0.4307 acc_train: 0.8067 loss_val: 0.3042 acc_val: 0.8947 time: 0.2339s\n",
            "Epoch: 0074 loss_train: 0.4283 acc_train: 0.8067 loss_val: 0.3032 acc_val: 0.8947 time: 0.2264s\n",
            "Epoch: 0075 loss_train: 0.4591 acc_train: 0.7600 loss_val: 0.3083 acc_val: 0.8947 time: 0.2316s\n",
            "Epoch: 0076 loss_train: 0.4071 acc_train: 0.8067 loss_val: 0.3189 acc_val: 0.8947 time: 0.2240s\n",
            "Epoch: 0077 loss_train: 0.4238 acc_train: 0.8200 loss_val: 0.3186 acc_val: 0.8947 time: 0.2304s\n",
            "Optimization Finished!\n",
            "Total time elapsed: 32.9369s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRAPH GENERATOR"
      ],
      "metadata": {
        "id": "UcFDzaHOpvxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OlikZDjJpDyU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "rollout = 10\n",
        "MAX_NUM_NODES = 29 # for mutag\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, model_path: str, C: list, node_feature_dim: int ,num_class = 2, c=0, hyp1=1, hyp2=2, start=None, nfeat=7, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param C: Candidate set of nodes (list)\n",
        "        :param start: Starting node (defaults to randomized node)\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__()\n",
        "        self.nfeat = nfeat\n",
        "        self.dropout = dropout\n",
        "        self.c = c # c is the specific class of graph to be generated\n",
        "\n",
        "        self.fc = nn.Linear(nfeat, 8)\n",
        "        self.gc1 = GraphConvolution(8, 16)\n",
        "        self.gc2 = GraphConvolution(16, 24)\n",
        "        self.gc3 = GraphConvolution(24, 32)\n",
        "\n",
        "        # MLP1\n",
        "        # 2 FC layers with hidden dimension 16\n",
        "        self.mlp1 = nn.Sequential(nn.Linear(32, 16), nn.Linear(16, 1))\n",
        "\n",
        "        # MLP2\n",
        "        # 2 FC layers with hidden dimension 24\n",
        "        self.mlp2 = nn.Sequential(nn.Linear(64, 24), nn.Linear(24, 1))\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.hyp1 = hyp1\n",
        "        self.hyp2 = hyp2\n",
        "        self.candidate_set = C\n",
        "\n",
        "        # Default starting node (if any)\n",
        "        if start != None:\n",
        "            self.start = start\n",
        "            self.random_start = False\n",
        "        else:\n",
        "            self.start = random.choice(np.arange(0, len(self.candidate_set)))\n",
        "            self.random_start = True\n",
        "\n",
        "        # Load GCN for calculating reward\n",
        "        self.model = GCN(nfeat=node_feature_dim,\n",
        "                         nclass=num_class,\n",
        "                         dropout=dropout)\n",
        "\n",
        "        self.model.load_state_dict(torch.load(model_path))\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.reset_graph()\n",
        "\n",
        "    def reset_graph(self):\n",
        "        \"\"\"\n",
        "        Reset g.G to default graph with only the start node, generate a graph containing only one node\n",
        "        \"\"\"\n",
        "        if self.random_start == True:\n",
        "            self.start = random.choice(np.arange(0, len(self.candidate_set)))\n",
        "\n",
        "        # In the initial graph, all nodes except the first one are masked. Since the adjacency matrix's edge length is MAX_NUM_NODES + len(self.candidate_set), not only the candidate nodes are masked, but also all virtual nodes in the graph\n",
        "        mask_start = torch.BoolTensor(\n",
        "            [False if i == 0 else True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\n",
        "\n",
        "        adj = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), MAX_NUM_NODES + len(self.candidate_set)),\n",
        "                          dtype=torch.float32)   # Here, the shape of adj is [MAX_NUM_NODES + len(self.candidate_set), MAX_NUM_NODES + len(self.candidate_set)], which may contain empty nodes\n",
        "\n",
        "        feat = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), len(self.candidate_set)), dtype=torch.float32)\n",
        "        # the first node in the feature matrix is the starting node -> one hot encoding to make its features\n",
        "        feat[0, self.start] = 1\n",
        "        # this fills the bottom part of node feature matrix \"x\" with the candidate nodes features (just the one hot encoding for each type of node)\n",
        "        feat[np.arange(-len(self.candidate_set), 0), np.arange(0, len(self.candidate_set))] = 1\n",
        "        # the remaining MAX_NUM_NODES - len(candidate_set) - 1(start node) features are empty, all zeros, since we start with a single node and the candidate set\n",
        "\n",
        "        degrees = torch.zeros(MAX_NUM_NODES)\n",
        "\n",
        "        self.G = {'adj': adj, 'feat': feat, 'degrees': degrees, 'num_nodes': 1, 'mask_start': mask_start}\n",
        "\n",
        "    ## Calculate Gt -> Gt+1\n",
        "    def forward(self, G_in):\n",
        "        ## G_in is Gt\n",
        "        G = copy.deepcopy(G_in)\n",
        "\n",
        "        x = G['feat'].detach().clone() # Feature matrix of Gt\n",
        "        adj = G['adj'].detach().clone() # Adjacency matrix of Gt\n",
        "\n",
        "        ## Corresponds to X = GCNs(Gt​,C)\n",
        "        x = F.relu6(self.fc(x))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu6(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu6(self.gc2(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu6(self.gc3(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        ## pt,start=Softmax(MLPs(X))\n",
        "        p_start = self.mlp1(x)\n",
        "        p_start = F.log_softmax(p_start, dim=0)\n",
        "        a_start_idx = torch.argmin(p_start.masked_fill(G['mask_start'].unsqueeze(1), +1))\n",
        "\n",
        "        ## pt,end=Softmax(MLPs([X,x^start​))\n",
        "        # broadcast\n",
        "        x1, x2 = torch.broadcast_tensors(x, x[a_start_idx])\n",
        "        x = torch.cat((x1, x2), 1)  # cat increases dim from 32 to 64\n",
        "\n",
        "        # Calculate mask_end, except for the candidate set and nodes in Gt that have not been selected as starting nodes, all others are masked\n",
        "        mask_end = torch.BoolTensor([True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\n",
        "        mask_end[MAX_NUM_NODES:] = False\n",
        "        mask_end[:G['num_nodes']] = False\n",
        "        mask_end[a_start_idx] = True\n",
        "\n",
        "        p_end = self.mlp2(x)\n",
        "        p_end = F.log_softmax(p_end, dim=0)\n",
        "        a_end_idx = torch.argmin(p_end.masked_fill(mask_end.unsqueeze(1), +1))\n",
        "        # Return new G\n",
        "        # If a_end_idx is not masked, the node exists in the graph, no new node added\n",
        "        if G['mask_start'][a_end_idx] == False:\n",
        "            G['adj'][a_end_idx][a_start_idx] += 1\n",
        "            G['adj'][a_start_idx][a_end_idx] += 1\n",
        "\n",
        "            # Update degrees\n",
        "            G['degrees'][a_start_idx] += 1\n",
        "            G['degrees'][a_end_idx] += 1 # ???? original line: G['degrees'][G['num_nodes']] += 1\n",
        "        else: # if end-node was chosen from candidate set:\n",
        "            # Add node\n",
        "            G['feat'][G['num_nodes']] = G['feat'][a_end_idx]\n",
        "            # Add edge\n",
        "            G['adj'][G['num_nodes']][a_start_idx] += 1\n",
        "            G['adj'][a_start_idx][G['num_nodes']] += 1\n",
        "            # Update degrees\n",
        "            G['degrees'][a_start_idx] += 1\n",
        "            G['degrees'][G['num_nodes']] += 1\n",
        "\n",
        "            # Update start mask\n",
        "            G_mask_start_copy = G['mask_start'].detach().clone()\n",
        "            G_mask_start_copy[G['num_nodes']] = False\n",
        "            G['mask_start'] = G_mask_start_copy\n",
        "\n",
        "            G['num_nodes'] += 1\n",
        "\n",
        "        return p_start, a_start_idx, p_end, a_end_idx, G\n",
        "\n",
        "\n",
        "    ### Reward function\n",
        "    def calculate_reward(self, G_t_1):\n",
        "        \"\"\"\n",
        "        Rtr     Calculated from graph rules to encourage generated graphs to be valid\n",
        "                1. Only one edge to be added between any two nodes\n",
        "                2. Generated graph cannot contain more nodes than predefined maximum node number\n",
        "                3. (For chemical) Degree cannot exceed valency\n",
        "                If generated graph violates graph rule, Rtr = -1\n",
        "\n",
        "        Rtf     Feedback from trained model\n",
        "        \"\"\"\n",
        "\n",
        "        rtr = self.check_graph_rules(G_t_1)\n",
        "\n",
        "        rtf = self.calculate_reward_feedback(G_t_1)\n",
        "        rtf_sum = 0\n",
        "        for m in range(rollout):\n",
        "            p_start, a_start, p_end, a_end, G_t_1 = self.forward(G_t_1)\n",
        "            rtf_sum += self.calculate_reward_feedback(G_t_1)\n",
        "        rtf = rtf + self.hyp1 * (rtf_sum / rollout)\n",
        "\n",
        "        return rtf + self.hyp2 * rtr\n",
        "\n",
        "    def calculate_reward_feedback(self, G_t_1):\n",
        "        \"\"\"\n",
        "        p(f(G_t_1) = c) - 1/l\n",
        "        where l denotes number of possible classes for f\n",
        "        \"\"\"\n",
        "        f = self.model(G_t_1['feat'], G_t_1['adj'])\n",
        "        return f[self.c] - 1 / len(f)\n",
        "\n",
        "\n",
        "    ## Graph rules\n",
        "    def check_graph_rules(self, G_t_1):\n",
        "        \"\"\"\n",
        "        For mutag, node degrees cannot exceed valency\n",
        "        \"\"\"\n",
        "        for idx, d in enumerate(G_t_1['degrees']):\n",
        "            if d != 0:\n",
        "                node_id = torch.argmax(G_t_1['feat'][idx])  # Eg. [0, 1, 0, 0] -> 1 (the index)\n",
        "                node = self.candidate_set[node_id]  # Eg ['C.4', 'F.2', 'Br.7'][1] = 'F.2'\n",
        "                max_valency = int(node.split('.')[1])  # Eg. C.4 -> ['C', '4'] -> 4\n",
        "\n",
        "                # If any node degree exceeds its valency, return -1\n",
        "                if max_valency < d:\n",
        "                    return -1\n",
        "\n",
        "        # if there are more than 1 edge between any 2 nodes, return -1\n",
        "        if torch.any(G_t_1['adj'] > 1):\n",
        "            return -1\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "    ## Calculate loss\n",
        "    def calculate_loss(self, Rt, p_start, a_start, p_end, a_end, G_t_1):\n",
        "        \"\"\"\n",
        "        Calculated from cross entropy loss (Lce) and reward function (Rt)\n",
        "        where loss = -Rt*(Lce_start + Lce_end)\n",
        "        \"\"\"\n",
        "\n",
        "        Lce_start = F.nll_loss(torch.reshape(p_start, (1, 36)), a_start.unsqueeze(0)) # nll since we have already computed log_softmax\n",
        "        Lce_end = F.nll_loss(torch.reshape(p_end, (1, 36)), a_end.unsqueeze(0))\n",
        "\n",
        "        return Rt * (Lce_start + Lce_end) # ???? original was -Rt * (Lce_start + Lce_end), with minus sign\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING GENERATOR"
      ],
      "metadata": {
        "id": "5eXvbB3Vp-2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train_generator(generator, num_episodes=1000, max_gen_step=10, learning_rate=0.01, b1=0.9, b2=0.999):\n",
        "    \"\"\"\n",
        "    Train the generator to produce graphs that maximize the target GNN's confidence for a given class.\n",
        "\n",
        "    :param generator: An instance of the Generator class\n",
        "    :param num_episodes: Number of training episodes\n",
        "    :param max_gen_step: Maximum steps for generating the graph (e.g., maximum number of nodes)\n",
        "    :param learning_rate: Learning rate for the optimizer\n",
        "    :param b1, b2: Beta parameters for Adam optimizer\n",
        "    \"\"\"\n",
        "    # Set up the optimizer\n",
        "    optimizer = optim.Adam(generator.parameters(), lr=learning_rate, betas=(b1, b2))\n",
        "    max_nodes = 4\n",
        "    # Training loop\n",
        "    for episode in range(num_episodes):\n",
        "        # Reset the graph to start from a single node\n",
        "        generator.reset_graph()\n",
        "\n",
        "        G = copy.deepcopy(generator.G)\n",
        "        Rt = 0\n",
        "\n",
        "        for step in range(max_gen_step):\n",
        "            # Forward pass: Generate the next step in the graph (Gt -> Gt+1)\n",
        "            p_start, a_start, p_end, a_end, G = generator.forward(G)\n",
        "\n",
        "            # Calculate the reward for the generated graph G_t+1\n",
        "            Rt = generator.calculate_reward(G)\n",
        "\n",
        "            # Calculate loss using the reward and generated probabilities\n",
        "            loss = generator.calculate_loss(Rt, p_start, a_start, p_end, a_end, G)\n",
        "\n",
        "            # Perform backpropagation and update the generator's parameters\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Check if the number of nodes exceeds the allowed max_gen_step\n",
        "            if G['num_nodes'] > max_nodes:\n",
        "                break\n",
        "\n",
        "        # Logging for debugging or monitoring training progress\n",
        "        if episode % 50 == 0:\n",
        "            print(f\"Episode {episode}/{num_episodes}, Total Loss: {loss.item()}, Reward: {Rt}\")\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize the Generator with the appropriate parameters\n",
        "    model_path = 'model/gcn_first.pth'\n",
        "    candidate_set = ['C.4', 'N.4', 'O.2', 'F.1', 'I.1', 'Cl.1', 'Br.1']\n",
        "    g = Generator(model_path=model_path, C=candidate_set, node_feature_dim=7, c=0, start=0)\n",
        "\n",
        "    # Train the generator\n",
        "    train_generator(g, num_episodes=1000, max_gen_step=15, learning_rate=0.01)\n"
      ],
      "metadata": {
        "id": "0-EdO52cEscM",
        "outputId": "4995601e-1240-45f4-de71-4e6d05d21a96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-2981db5d6084>:55: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0/1000, Total Loss: 1.2224656343460083, Reward: 0.1707206517457962\n",
            "Episode 50/1000, Total Loss: -2606795.0, Reward: -3.0\n",
            "Episode 100/1000, Total Loss: -10502520.0, Reward: -3.0\n",
            "Episode 150/1000, Total Loss: -22727916.0, Reward: -3.0\n",
            "Episode 200/1000, Total Loss: -35941432.0, Reward: -3.0\n",
            "Episode 250/1000, Total Loss: -55952776.0, Reward: -3.0\n",
            "Episode 300/1000, Total Loss: -74123784.0, Reward: -3.0\n",
            "Episode 350/1000, Total Loss: -100970608.0, Reward: -2.995516300201416\n",
            "Episode 400/1000, Total Loss: -122182888.0, Reward: -2.999833583831787\n",
            "Episode 450/1000, Total Loss: -151933920.0, Reward: -2.998811721801758\n",
            "Episode 500/1000, Total Loss: -174163104.0, Reward: -3.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-96cea227a408>\u001b[0m in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Train the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_gen_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-96cea227a408>\u001b[0m in \u001b[0;36mtrain_generator\u001b[0;34m(generator, num_episodes, max_gen_step, learning_rate, b1, b2)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Calculate the reward for the generated graph G_t+1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mRt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Calculate loss using the reward and generated probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-2981db5d6084>\u001b[0m in \u001b[0;36mcalculate_reward\u001b[0;34m(self, G_t_1)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mrtf_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mp_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_t_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_t_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m             \u001b[0mrtf_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_reward_feedback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_t_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mrtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrtf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyp1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrtf_sum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrollout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-2981db5d6084>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, G_in)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"dropout probability has to be between 0 and 1, but got {p}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m     return (\n\u001b[0;32m-> 1425\u001b[0;31m         \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m     )\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Draw the graph\n",
        "def display_graph(G):\n",
        "    G_nx = nx.from_numpy_array(np.asmatrix(G['adj'][:G['num_nodes'], :G['num_nodes']].numpy()))\n",
        "    # nx.draw_networkx(G_nx)\n",
        "\n",
        "    layout = nx.spring_layout(G_nx)\n",
        "    nx.draw(G_nx, layout)\n",
        "\n",
        "    coloring = torch.argmax(G['feat'], 1)\n",
        "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']\n",
        "\n",
        "    for i in range(7):\n",
        "        nx.draw_networkx_nodes(G_nx, pos=layout, nodelist=[x for x in G_nx.nodes() if coloring[x] == i], node_color=colors[i])\n",
        "        nx.draw_networkx_labels(G_nx, pos=layout, labels={x: candidate_set[i].split('.')[0] for x in G_nx.nodes() if coloring[x] == i})\n",
        "    nx.draw_networkx_edges(G_nx, pos=layout, width=list(nx.get_edge_attributes(G_nx, 'weight').values()))\n",
        "    nx.draw_networkx_edge_labels(G_nx, pos=layout, edge_labels=nx.get_edge_attributes(G_nx, \"weight\"))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "tIhHEUZGdFwA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate a graph after training is complete\n",
        "def generate_graph(generator, max_gen_step=15):\n",
        "    \"\"\"\n",
        "    Generate a graph using the trained generator.\n",
        "\n",
        "    :param generator: An instance of the trained Generator class\n",
        "    :param max_gen_step: Maximum number of steps for generating the graph.\n",
        "    :return: Generated graph G\n",
        "    \"\"\"\n",
        "    # Reset graph to start from a single node\n",
        "    generator.reset_graph()\n",
        "    max_nodes = 4\n",
        "\n",
        "    G = copy.deepcopy(generator.G)\n",
        "\n",
        "    for step in range(max_gen_step):\n",
        "        # Generate next step in the graph (Gt -> Gt+1)\n",
        "        _, _, _, _, G = generator.forward(G)\n",
        "\n",
        "        # Stop if the number of nodes exceeds max_gen_step\n",
        "        if G['num_nodes'] > max_nodes:\n",
        "            break\n",
        "\n",
        "    return G"
      ],
      "metadata": {
        "id": "fD7sAJn9KMRt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_display = generate_graph(g)\n",
        "display_graph(to_display)\n",
        "print(g.model(to_display['feat'], to_display['adj']))"
      ],
      "metadata": {
        "id": "oGU7yiv363x-",
        "outputId": "179c968e-12e3-4c60-c439-f2d51e55ba8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5910, 0.4090])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST"
      ],
      "metadata": {
        "id": "iyczD_VhqLWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Load_dataset import load_split_MUTAG_data, accuracy\n",
        "from Model import GCN\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_path = 'model/gcn_first.pth'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    adj_list, features_list, graph_labels, idx_map, idx_train, idx_val, idx_test = load_split_MUTAG_data()\n",
        "    model = GCN(nfeat=features_list[0].shape[1],  # nfeat = 7\n",
        "                nclass=graph_labels.max().item() + 1,  # nclass = 2\n",
        "                dropout=0.1)\n",
        "\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    for i in idx_test:\n",
        "        output = model(features_list[i], adj_list[i])\n",
        "        output = output.unsqueeze(0)\n",
        "        outputs.append(output)\n",
        "    output = torch.cat(outputs, dim=0)\n",
        "\n",
        "    loss_test = F.cross_entropy(output, graph_labels[idx_test])\n",
        "    acc_test = accuracy(output, graph_labels[idx_test])\n",
        "    print(loss_test)\n",
        "    print(acc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "6poe4hoUqMWr",
        "outputId": "815edafd-d8a1-46e8-df57-d8933edada84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'Load_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-11e0ad6d56c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLoad_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_split_MUTAG_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Load_dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}