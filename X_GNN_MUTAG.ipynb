{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "2WbgJ3vqr0TE"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alessioborgi/RL_Project/blob/main/X_GNN_MUTAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# X-GNN: Model-Explanations of GNNs using RL\n",
        "\n",
        "### *Alessio Borgi*\n",
        "### *Francesco Danese*"
      ],
      "metadata": {
        "id": "JUUvLA8lri-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0: INSTALLING & IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "2WbgJ3vqr0TE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric networkx matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE7aTsSLrdMk",
        "outputId": "4d7f81ed-7e9c-451a-ec75-6c6e7f7c630d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.4.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.11.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import networkx as nx\n",
        "from torch.nn import Linear\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import plotly.graph_objects as go\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.utils import to_networkx, to_dense_adj\n",
        "from torch_geometric.utils import add_self_loops, remove_self_loops, degree"
      ],
      "metadata": {
        "id": "H6kL0ndKrzz3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensures that dataset splitting, model initialization, and training are deterministic.\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)  # Fix seed for PyTorch (CPU).\n",
        "    torch.cuda.manual_seed(seed)  # Fix seed for PyTorch (GPU).\n",
        "    torch.cuda.manual_seed_all(seed)  # Fix seed for all GPUs.\n",
        "    np.random.seed(seed)  # Fix seed for NumPy.\n",
        "    random.seed(seed)  # Fix seed for Python's random module.\n",
        "    torch.backends.cudnn.deterministic = True  # Ensure deterministic GPU behavior.\n",
        "    torch.backends.cudnn.benchmark = False  # Disable cuDNN auto-tuning to enforce determinism.\n",
        "\n",
        "set_seed(42)  # Set seed to ensure reproducibility across runs."
      ],
      "metadata": {
        "id": "FV3Oe3Ogr6Gi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1: DATASET EXPLORATION"
      ],
      "metadata": {
        "id": "tUwpo2PYr85a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MUTAG Dataset.\n",
        "dataset = TUDataset(root='data/TUDataset', name='MUTAG')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoK2Qv1wr_G8",
        "outputId": "1f650b64-a98c-4cfa-d528-6cf53b865381"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to collect dataset-wide statistics.\n",
        "num_nodes = []\n",
        "num_edges = []\n",
        "labels = []\n",
        "\n",
        "# Gather data about all graphs.\n",
        "for data in dataset:\n",
        "    num_nodes.append(data.num_nodes)\n",
        "    num_edges.append(data.num_edges)\n",
        "    labels.append(data.y.item())\n",
        "\n",
        "# Create a summary DataFrame.\n",
        "df = pd.DataFrame({\n",
        "    \"Graph ID\": range(len(dataset)),\n",
        "    \"Num Nodes\": num_nodes,\n",
        "    \"Num Edges\": num_edges,\n",
        "    \"Label\": labels\n",
        "})\n",
        "\n",
        "# Dataset Statistics.\n",
        "print()\n",
        "print(f'Dataset: {dataset}:')\n",
        "print('====================')\n",
        "print(f\"Number of Graphs: {len(dataset)}\")\n",
        "print(f\"Number of Classes: {dataset.num_classes}\")\n",
        "print(f\"Average Nodes per Graph: {sum(num_nodes)/len(num_nodes):.2f}\")\n",
        "print(f\"Average Edges per Graph: {sum(num_edges)/len(num_edges):.2f}\")\n",
        "print(\"Class Distribution:\")\n",
        "print(df['Label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjM6AWy2sBux",
        "outputId": "4e778963-7104-4c8d-fc2d-b5275409bae9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset: MUTAG(188):\n",
            "====================\n",
            "Number of Graphs: 188\n",
            "Number of Classes: 2\n",
            "Average Nodes per Graph: 17.93\n",
            "Average Edges per Graph: 39.59\n",
            "Class Distribution:\n",
            "Label\n",
            "1    125\n",
            "0     63\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot class distribution using Plotly.\n",
        "class_counts = df['Label'].value_counts().reset_index()\n",
        "class_counts.columns = ['Label', 'Count']\n",
        "\n",
        "fig = px.bar(\n",
        "    class_counts,\n",
        "    x='Label', y='Count',\n",
        "    labels={\"Label\": \"Class Label\", \"Count\": \"Count\"},\n",
        "    title=\"Class Distribution in MUTAG Dataset\"\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "fKGtzVSjsDoF",
        "outputId": "2d30eaae-2092-4f89-f8b1-7eb1f85fd7de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"dd3e7baf-4013-48af-b43e-471120d63d20\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"dd3e7baf-4013-48af-b43e-471120d63d20\")) {                    Plotly.newPlot(                        \"dd3e7baf-4013-48af-b43e-471120d63d20\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Class Label=%{x}\\u003cbr\\u003eCount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[1,0],\"xaxis\":\"x\",\"y\":[125,63],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Class Label\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Class Distribution in MUTAG Dataset\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('dd3e7baf-4013-48af-b43e-471120d63d20');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the first graph of the Dataset.\n",
        "single_graph = dataset[0]\n",
        "print()\n",
        "print(single_graph)\n",
        "print('=============================================================')\n",
        "\n",
        "# Gather some statistics about the first graph.\n",
        "print(f'Number of nodes: {single_graph.num_nodes}')\n",
        "print(f'Number of edges: {single_graph.num_edges}')\n",
        "print(f'Average node degree: {single_graph.num_edges / single_graph.num_nodes:.2f}')\n",
        "print(f'Has isolated nodes: {single_graph.has_isolated_nodes()}')\n",
        "print(f'Has self-loops: {single_graph.has_self_loops()}')\n",
        "print(f'Is undirected: {single_graph.is_undirected()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tmgyk5Lhszvv",
        "outputId": "c27ae281-fa9a-4787-a675-0ce25054ae40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
            "=============================================================\n",
            "Number of nodes: 17\n",
            "Number of edges: 38\n",
            "Average node degree: 2.24\n",
            "Has isolated nodes: False\n",
            "Has self-loops: False\n",
            "Is undirected: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import plotly.graph_objs as go\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you already have the graph data loaded as `single_graph`\n",
        "# Convert the first graph in the dataset to NetworkX.\n",
        "G = to_networkx(single_graph, to_undirected=True)\n",
        "\n",
        "# Extract the node feature matrix\n",
        "node_features = single_graph.x  # Shape: [num_nodes, num_features]\n",
        "\n",
        "# Convert one-hot encoded node features to atom types (indices)\n",
        "node_colors = torch.argmax(node_features, dim=1).numpy()\n",
        "\n",
        "# Define a colormap for different atom types\n",
        "cmap = plt.get_cmap(\"tab10\")  # You can choose any matplotlib colormap\n",
        "unique_atom_types = np.unique(node_colors)\n",
        "colors = {atom_type: cmap(i / len(unique_atom_types)) for i, atom_type in enumerate(unique_atom_types)}\n",
        "\n",
        "# Generate 2D layout\n",
        "pos_2d = nx.spring_layout(G, seed=42)\n",
        "\n",
        "# Prepare edge trace for 2D visualization\n",
        "edge_x_2d = []\n",
        "edge_y_2d = []\n",
        "for edge in G.edges():\n",
        "    x0, y0 = pos_2d[edge[0]]\n",
        "    x1, y1 = pos_2d[edge[1]]\n",
        "    edge_x_2d.extend([x0, x1, None])\n",
        "    edge_y_2d.extend([y0, y1, None])\n",
        "\n",
        "edge_trace_2d = go.Scatter(\n",
        "    x=edge_x_2d, y=edge_y_2d,\n",
        "    line=dict(width=0.5, color='#888'),\n",
        "    hoverinfo='none',\n",
        "    mode='lines'\n",
        ")\n",
        "\n",
        "# Prepare node trace for 2D visualization\n",
        "node_x_2d = []\n",
        "node_y_2d = []\n",
        "node_labels = []\n",
        "node_colors_plotly = []\n",
        "\n",
        "for node in G.nodes():\n",
        "    x, y = pos_2d[node]\n",
        "    node_x_2d.append(x)\n",
        "    node_y_2d.append(y)\n",
        "    atom_type_list = ['C', 'N', 'O', 'F', 'I', 'Cl', 'Br']\n",
        "    atom_type = atom_type_list[node_colors[node]]\n",
        "    node_labels.append(f\"{atom_type}\")\n",
        "    rgba_color = colors[node_colors[node]]\n",
        "    plotly_color = f\"rgba({rgba_color[0] * 255}, {rgba_color[1] * 255}, {rgba_color[2] * 255}, {rgba_color[3]})\"\n",
        "    node_colors_plotly.append(plotly_color)\n",
        "\n",
        "node_trace_2d = go.Scatter(\n",
        "    x=node_x_2d, y=node_y_2d,\n",
        "    mode='markers+text',\n",
        "    hoverinfo='text',\n",
        "    marker=dict(\n",
        "        size=10,\n",
        "        color=node_colors_plotly,\n",
        "    ),\n",
        "    text=node_labels,\n",
        "    textposition=\"top center\"\n",
        ")\n",
        "\n",
        "# 2D Visualization\n",
        "fig_2d = go.Figure(data=[edge_trace_2d, node_trace_2d],\n",
        "                   layout=go.Layout(\n",
        "                       title=\"2D Visualization of Graph 0\",\n",
        "                       showlegend=False,\n",
        "                       hovermode='closest',\n",
        "                       margin=dict(b=0, l=0, r=0, t=40),\n",
        "                       xaxis=dict(showgrid=False, zeroline=False),\n",
        "                       yaxis=dict(showgrid=False, zeroline=False)\n",
        "                   ))\n",
        "fig_2d.show()\n",
        "\n",
        "# Analyze graph properties\n",
        "print(f\"Number of nodes: {single_graph.num_nodes}\")\n",
        "print(f\"Number of edges: {single_graph.num_edges}\")\n",
        "print(f\"Is graph directed? {single_graph.is_directed()}\")\n",
        "print(f\"Graph label: {single_graph.y}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "kf8xM0wOsFi7",
        "outputId": "38e39f59-06e1-46a9-fe71-f48dadc02f84"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d2175152-7ddb-46c2-b2d9-b1950e874299\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d2175152-7ddb-46c2-b2d9-b1950e874299\")) {                    Plotly.newPlot(                        \"d2175152-7ddb-46c2-b2d9-b1950e874299\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[-0.3727182492900634,-0.5510840196249834,null,-0.3727182492900634,-0.2299887901282408,null,-0.5510840196249834,-0.5438804985577245,null,-0.5438804985577245,-0.3766813157901222,null,-0.3766813157901222,-0.20885686146700344,null,-0.3766813157901222,-0.2665553478854011,null,-0.20885686146700344,-0.2299887901282408,null,-0.20885686146700344,-0.016589072446311765,null,-0.016589072446311765,0.04449844969654987,null,0.04449844969654987,-0.004549900306905611,null,-0.004549900306905611,-0.2665553478854011,null,-0.004549900306905611,0.17349067894459028,null,-0.2665553478854011,-0.20909489834523434,null,-0.20909489834523434,0.006577112790116703,null,0.006577112790116703,0.30487213864738016,null,0.30487213864738016,0.17349067894459028,null,0.30487213864738016,0.6260641640669481,null,0.6260641640669481,0.7958900025590367,null,0.6260641640669481,0.8286064071373688,null],\"y\":[1.0,0.8570191093083964,null,1.0,0.828528558137815,null,0.8570191093083964,0.5802363441080655,null,0.5802363441080655,0.30682370852924457,null,0.30682370852924457,0.5429957606160726,null,0.30682370852924457,-0.0705188995613755,null,0.5429957606160726,0.828528558137815,null,0.5429957606160726,0.3753641564577354,null,0.3753641564577354,0.12135433599050012,null,0.12135433599050012,-0.1484296524723047,null,-0.1484296524723047,-0.0705188995613755,null,-0.1484296524723047,-0.40582669457225157,null,-0.0705188995613755,-0.3993931571933171,null,-0.3993931571933171,-0.6191922903997025,null,-0.6191922903997025,-0.6515404053515196,null,-0.6515404053515196,-0.40582669457225157,null,-0.6515404053515196,-0.7588467657998171,null,-0.7588467657998171,-0.9358164791562336,null,-0.7588467657998171,-0.6227576286413062,null],\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(31.0, 119.0, 180.0, 1.0)\",\"rgba(214.0, 39.0, 40.0, 1.0)\",\"rgba(227.0, 119.0, 194.0, 1.0)\",\"rgba(227.0, 119.0, 194.0, 1.0)\"],\"size\":10},\"mode\":\"markers+text\",\"text\":[\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"N\",\"O\",\"O\"],\"textposition\":\"top center\",\"x\":[-0.3727182492900634,-0.5510840196249834,-0.5438804985577245,-0.3766813157901222,-0.20885686146700344,-0.2299887901282408,-0.016589072446311765,0.04449844969654987,-0.004549900306905611,-0.2665553478854011,-0.20909489834523434,0.006577112790116703,0.30487213864738016,0.17349067894459028,0.6260641640669481,0.7958900025590367,0.8286064071373688],\"y\":[1.0,0.8570191093083964,0.5802363441080655,0.30682370852924457,0.5429957606160726,0.828528558137815,0.3753641564577354,0.12135433599050012,-0.1484296524723047,-0.0705188995613755,-0.3993931571933171,-0.6191922903997025,-0.6515404053515196,-0.40582669457225157,-0.7588467657998171,-0.9358164791562336,-0.6227576286413062],\"type\":\"scatter\"}],                        {\"hovermode\":\"closest\",\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":40},\"showlegend\":false,\"title\":{\"text\":\"2D Visualization of Graph 0\"},\"xaxis\":{\"showgrid\":false,\"zeroline\":false},\"yaxis\":{\"showgrid\":false,\"zeroline\":false},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d2175152-7ddb-46c2-b2d9-b1950e874299');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 17\n",
            "Number of edges: 38\n",
            "Is graph directed? False\n",
            "Graph label: tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import plotly.graph_objs as go\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "single_graph = dataset[4]\n",
        "# Assuming you already have the graph data loaded as `single_graph`\n",
        "# Convert the first graph in the dataset to NetworkX.\n",
        "G = to_networkx(single_graph, to_undirected=True)\n",
        "\n",
        "# Extract the node feature matrix\n",
        "node_features = single_graph.x  # Shape: [num_nodes, num_features]\n",
        "\n",
        "# Convert one-hot encoded node features to atom types (indices)\n",
        "node_colors = torch.argmax(node_features, dim=1).numpy()\n",
        "\n",
        "# Define atom labels and fixed colormap\n",
        "atom_labels = ['C', 'N', 'O', 'F', 'I', 'Cl', 'Br']\n",
        "fixed_colors = {\n",
        "    'C': 'rgba(0, 255, 0, 1)',  # Green\n",
        "    'N': 'rgba(255, 0, 0, 1)',  # Red\n",
        "    'O': 'rgba(0, 0, 255, 1)',  # Blue\n",
        "    'F': 'rgba(255, 255, 0, 1)',  # Yellow\n",
        "    'I': 'rgba(128, 0, 128, 1)',  # Purple\n",
        "    'Cl': 'rgba(255, 165, 0, 1)',  # Orange\n",
        "    'Br': 'rgba(75, 0, 130, 1)'   # Indigo\n",
        "}\n",
        "\n",
        "# Generate 3D layout\n",
        "pos_3d = nx.spring_layout(G, dim=3, seed=42)\n",
        "\n",
        "# Extract node labels based on atom types\n",
        "node_labels = []\n",
        "node_colors_plotly = []\n",
        "for node in G.nodes():\n",
        "    atom_type = atom_labels[node_colors[node]]\n",
        "    node_labels.append(atom_type)\n",
        "    plotly_color = fixed_colors[atom_type]\n",
        "    node_colors_plotly.append(plotly_color)\n",
        "\n",
        "# Prepare edge trace for 3D visualization\n",
        "edge_x_3d = []\n",
        "edge_y_3d = []\n",
        "edge_z_3d = []\n",
        "for edge in G.edges():\n",
        "    x0, y0, z0 = pos_3d[edge[0]]\n",
        "    x1, y1, z1 = pos_3d[edge[1]]\n",
        "    edge_x_3d.extend([x0, x1, None])\n",
        "    edge_y_3d.extend([y0, y1, None])\n",
        "    edge_z_3d.extend([z0, z1, None])\n",
        "\n",
        "edge_trace_3d = go.Scatter3d(\n",
        "    x=edge_x_3d, y=edge_y_3d, z=edge_z_3d,\n",
        "    line=dict(width=0.5, color='#888'),\n",
        "    hoverinfo='none',\n",
        "    mode='lines'\n",
        ")\n",
        "\n",
        "# Prepare node trace for 3D visualization\n",
        "node_x_3d = []\n",
        "node_y_3d = []\n",
        "node_z_3d = []\n",
        "for node in G.nodes():\n",
        "    x, y, z = pos_3d[node]\n",
        "    node_x_3d.append(x)\n",
        "    node_y_3d.append(y)\n",
        "    node_z_3d.append(z)\n",
        "\n",
        "node_trace_3d = go.Scatter3d(\n",
        "    x=node_x_3d, y=node_y_3d, z=node_z_3d,\n",
        "    mode='markers+text',\n",
        "    hoverinfo='text',\n",
        "    marker=dict(\n",
        "        size=10,\n",
        "        color=node_colors_plotly,\n",
        "    ),\n",
        "    text=node_labels,\n",
        "    textposition=\"top center\"\n",
        ")\n",
        "\n",
        "# 3D Visualization\n",
        "fig_3d = go.Figure(data=[edge_trace_3d, node_trace_3d],\n",
        "                   layout=go.Layout(\n",
        "                       title=\"3D Visualization of Graph 0\",\n",
        "                       showlegend=False,\n",
        "                       margin=dict(b=0, l=0, r=0, t=40),\n",
        "                       scene=dict(\n",
        "                           xaxis=dict(showticklabels=False),\n",
        "                           yaxis=dict(showticklabels=False),\n",
        "                           zaxis=dict(showticklabels=False)\n",
        "                       )\n",
        "                   ))\n",
        "fig_3d.show()\n",
        "\n",
        "# Analyze graph properties\n",
        "print(f\"Number of nodes: {single_graph.num_nodes}\")\n",
        "print(f\"Number of edges: {single_graph.num_edges}\")\n",
        "print(f\"Is graph directed? {single_graph.is_directed()}\")\n",
        "print(f\"Graph label: {single_graph.y}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "8dRhlu6ZsP6R",
        "outputId": "6b23ff52-0896-4405-d718-123e86a93142"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"181b5c9e-6623-4e87-8e50-95fddc115165\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"181b5c9e-6623-4e87-8e50-95fddc115165\")) {                    Plotly.newPlot(                        \"181b5c9e-6623-4e87-8e50-95fddc115165\",                        [{\"hoverinfo\":\"none\",\"line\":{\"color\":\"#888\",\"width\":0.5},\"mode\":\"lines\",\"x\":[0.02458546069025762,-0.2497724533846732,null,0.02458546069025762,0.3506783398707835,null,-0.2497724533846732,-0.33870899413810185,null,-0.33870899413810185,-0.007160738692036449,null,-0.33870899413810185,-0.6893228619804218,null,-0.007160738692036449,0.2481327865347945,null,-0.007160738692036449,0.018497996295593084,null,0.2481327865347945,0.3506783398707835,null,0.3506783398707835,0.5873156864975905,null,0.018497996295593084,-0.08369490102825228,null,0.018497996295593084,0.13944967933446725,null],\"y\":[-0.13351455396521839,-0.050148520252982914,null,-0.13351455396521839,-0.1888365195744066,null,-0.050148520252982914,0.0059437570218711195,null,0.0059437570218711195,0.048923917773303786,null,0.0059437570218711195,-0.010695959720479414,null,0.048923917773303786,-0.0775316434784458,null,0.048923917773303786,0.183619246357252,null,-0.0775316434784458,-0.1888365195744066,null,-0.1888365195744066,-0.3092693102440526,null,0.183619246357252,0.40499888411238844,null,0.183619246357252,0.12651070197077038,null],\"z\":[0.6640739399357102,0.45847939511230384,null,0.6640739399357102,0.5594011291999086,null,0.45847939511230384,0.0871366963812924,null,0.0871366963812924,-0.1966109723140789,null,0.0871366963812924,0.07226906111168803,null,-0.1966109723140789,0.1586094094460366,null,-0.1966109723140789,-0.6772928364646472,null,0.1586094094460366,0.5594011291999086,null,0.5594011291999086,0.8034406719279515,null,-0.6772928364646472,-0.9295064943361648,null,-0.6772928364646472,-1.0,null],\"type\":\"scatter3d\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":[\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(0, 255, 0, 1)\",\"rgba(255, 255, 0, 1)\",\"rgba(255, 0, 0, 1)\",\"rgba(0, 0, 255, 1)\",\"rgba(0, 0, 255, 1)\",\"rgba(255, 255, 0, 1)\"],\"size\":10},\"mode\":\"markers+text\",\"text\":[\"C\",\"C\",\"C\",\"C\",\"C\",\"C\",\"F\",\"N\",\"O\",\"O\",\"F\"],\"textposition\":\"top center\",\"x\":[0.02458546069025762,-0.2497724533846732,-0.33870899413810185,-0.007160738692036449,0.2481327865347945,0.3506783398707835,0.5873156864975905,0.018497996295593084,-0.08369490102825228,0.13944967933446725,-0.6893228619804218],\"y\":[-0.13351455396521839,-0.050148520252982914,0.0059437570218711195,0.048923917773303786,-0.0775316434784458,-0.1888365195744066,-0.3092693102440526,0.183619246357252,0.40499888411238844,0.12651070197077038,-0.010695959720479414],\"z\":[0.6640739399357102,0.45847939511230384,0.0871366963812924,-0.1966109723140789,0.1586094094460366,0.5594011291999086,0.8034406719279515,-0.6772928364646472,-0.9295064943361648,-1.0,0.07226906111168803],\"type\":\"scatter3d\"}],                        {\"margin\":{\"b\":0,\"l\":0,\"r\":0,\"t\":40},\"scene\":{\"xaxis\":{\"showticklabels\":false},\"yaxis\":{\"showticklabels\":false},\"zaxis\":{\"showticklabels\":false}},\"showlegend\":false,\"title\":{\"text\":\"3D Visualization of Graph 0\"},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('181b5c9e-6623-4e87-8e50-95fddc115165');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 11\n",
            "Number of edges: 22\n",
            "Is graph directed? False\n",
            "Graph label: tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for d in dataset:\n",
        "  if d.x[:, 4].sum().item() > 0:\n",
        "    print(i)\n",
        "  i+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ojHYP6z7XqZ",
        "outputId": "598dde26-93a0-47ae-9fc3-9d231ca16a5c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.shuffle()\n",
        "\n",
        "train_dataset = dataset[:150]\n",
        "test_dataset = dataset[150:]\n",
        "\n",
        "print(f'Number of training graphs: {len(train_dataset)}')\n",
        "print(f'Number of test graphs: {len(test_dataset)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj6g8d1YsXOO",
        "outputId": "375e6ad9-b5e8-419a-951e-6beaefb1ebd2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training graphs: 150\n",
            "Number of test graphs: 38\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PARTE DEL CINESE\n"
      ],
      "metadata": {
        "id": "DsjhJdjdpibq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "\n",
        "\n",
        "# MUTAG dataset features: 188 graphs, totaling 3371 nodes, 7442 edges, represented as an undirected graph\n",
        "\n",
        "def encode_onehot(labels):\n",
        "    classes = set(labels)\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
        "                    enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
        "                             dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def load_split_MUTAG_data(path=\"/content/datas/\", dataset=\"MUTAG_\", split_train=0.7, split_val=0.15):\n",
        "    \"\"\"Load MUTAG data\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    # Load graph labels\n",
        "    graph_labels = np.genfromtxt(\"{}{}graph_labels.txt\".format(path, dataset),\n",
        "                                 dtype=np.dtype(int))\n",
        "    graph_labels = encode_onehot(graph_labels)  # (188, 2)\n",
        "    graph_labels = torch.LongTensor(np.where(graph_labels)[1])  # (188, 1)\n",
        "\n",
        "    # Graph node indices\n",
        "    graph_idx = np.genfromtxt(\"{}{}graph_indicator.txt\".format(path, dataset),\n",
        "                              dtype=np.dtype(int))\n",
        "\n",
        "    graph_idx = np.array(graph_idx, dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(graph_idx)}  # key, value indicates the starting node index of the graph key is value\n",
        "    length = len(idx_map.keys())  # Total number of graphs\n",
        "    num_nodes = [idx_map[n] - idx_map[n - 1] if n - 1 > 1 else idx_map[n] for n in range(1, length + 1)]  # A list of length 188 representing the number of nodes in each graph\n",
        "    max_num_nodes = max(num_nodes)  # Maximum number of nodes in a single graph\n",
        "    features_list = []\n",
        "    adj_list = []\n",
        "    prev = 0\n",
        "\n",
        "    # Node labels\n",
        "    nodeidx_features = np.genfromtxt(\"{}{}node_labels.txt\".format(path, dataset), delimiter=\",\",\n",
        "                                     dtype=np.dtype(int))\n",
        "    node_features = np.zeros((nodeidx_features.shape[0], max(nodeidx_features) + 1))\n",
        "    node_features[np.arange(nodeidx_features.shape[0]), nodeidx_features] = 1\n",
        "\n",
        "    # Edge information\n",
        "    edges_unordered = np.genfromtxt(\"{}{}A.txt\".format(path, dataset), delimiter=\",\",\n",
        "                                    dtype=np.int32)\n",
        "\n",
        "    # Edge labels\n",
        "    edges_label = np.genfromtxt(\"{}{}edge_labels.txt\".format(path, dataset), delimiter=\",\",\n",
        "                                dtype=np.int32)  # shape = (7442,)\n",
        "\n",
        "    # Generate adjacency matrix A, which includes all edges in the dataset\n",
        "    adj = sp.coo_matrix((edges_label, (edges_unordered[:, 0] - 1, edges_unordered[:, 1] - 1)))\n",
        "\n",
        "    # Formula in the paper: A^ = (D~)^0.5 A~ (D~)^0.5\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    node_features = normalize(node_features)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))  # Corresponds to the formula A~ = A + IN\n",
        "    adj = adj.todense()\n",
        "\n",
        "    for n in range(1, length + 1):\n",
        "        # 'entry' is the feature matrix X for the n-th graph\n",
        "        entry = np.zeros((max_num_nodes, max(nodeidx_features) + 1))\n",
        "        entry[:idx_map[n] - prev] = node_features[prev:idx_map[n]]\n",
        "        entry = torch.FloatTensor(entry)\n",
        "        features_list.append(entry.tolist())\n",
        "\n",
        "        # 'entry' is the adjacency matrix A for the n-th graph\n",
        "        entry = np.zeros((max_num_nodes, max_num_nodes))\n",
        "        entry[:idx_map[n] - prev, :idx_map[n] - prev] = adj[prev:idx_map[n], prev:idx_map[n]]\n",
        "        entry = torch.FloatTensor(entry)\n",
        "        adj_list.append(entry.tolist())\n",
        "\n",
        "        prev = idx_map[n]  # 'prev' is the starting node index for the next graph\n",
        "\n",
        "    num_total = max(graph_idx)\n",
        "    num_train = int(split_train * num_total)\n",
        "    num_val = int((split_train + split_val) * num_total)\n",
        "\n",
        "    if (num_train == num_val or num_val == num_total):\n",
        "        return\n",
        "\n",
        "    features_list = torch.FloatTensor(features_list)\n",
        "    adj_list = torch.FloatTensor(adj_list)\n",
        "\n",
        "    idx_train = range(num_train)\n",
        "    idx_val = range(num_train, num_val)\n",
        "    idx_test = range(num_val, num_total)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    # Return values in order: adjacency matrices list of 188 graphs, feature matrices list of 188 graphs, labels of 188 graphs, starting node index of each graph, training set indices, validation set indices, test set indices\n",
        "    return adj_list, features_list, graph_labels, idx_map, idx_train, idx_val, idx_test\n"
      ],
      "metadata": {
        "id": "OMFErq4cpnKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GNN MODEL"
      ],
      "metadata": {
        "id": "ztZVpElEp1NI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model to Explain (GCN)\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "class GraphConvolution(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    paper: Semi-Supervised Classification with Graph Convolutional Networks\n",
        "    \"\"\"\n",
        "    # The parameters of the model include weight and bias\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))  # Weight matrix for the GCN layer\n",
        "        self.bias = Parameter(torch.FloatTensor(out_features))  # Bias term for the GCN layer\n",
        "        self.reset_parameters()  # Initialize parameters\n",
        "\n",
        "    # Weight initialization\n",
        "    def reset_parameters(self):\n",
        "        # Initialize weights and biases using uniform distribution based on the size of the output features\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    # Representation function, similar to __str__\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "    # Compute A~ X W(0), where A~ is the normalized adjacency matrix and X is the input feature matrix\n",
        "    def forward(self, input, adj):\n",
        "        # input.shape = [num_nodes, features] = X\n",
        "        # adj.shape = [num_nodes, num_nodes] = A~\n",
        "        # torch.mm(a, b) performs matrix multiplication of a and b, torch.mul(a, b) performs element-wise multiplication (a and b must have the same dimensions)\n",
        "        support = torch.mm(input, self.weight)  # Matrix multiplication of input features with weights, shape = [max_node, out_features]\n",
        "        output = torch.spmm(adj, support)  # Multiply normalized adjacency matrix with the support matrix, shape = [max_node, out_features]\n",
        "        return output + self.bias  # Add bias term, shape = [max_node, out_features]\n",
        "\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    # nfeat: number of input features, nclass: number of classes for classification, dropout: dropout rate\n",
        "    def __init__(self, nfeat, nclass, dropout):\n",
        "        \"\"\" As per paper \"\"\"\n",
        "        \"\"\" 3 layers of GCNs with output dimensions equal to 32, 48, 64 respectively and average all node features \"\"\"\n",
        "        \"\"\" Final classifier with 2 fully connected layers and hidden dimension set to 32 \"\"\"\n",
        "        \"\"\" Activation function - ReLu (Mutag) \"\"\"\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        # Define three GCN layers with increasing output dimensions\n",
        "        self.gc1 = GraphConvolution(nfeat, 32)  # First GCN layer (input features -> 32)\n",
        "        self.gc2 = GraphConvolution(32, 48)  # Second GCN layer (32 -> 48)\n",
        "        self.gc3 = GraphConvolution(48, 64)  # Third GCN layer (48 -> 64)\n",
        "\n",
        "        # Define two fully connected (linear) layers for classification\n",
        "        self.fc1 = nn.Linear(64, 32)  # First fully connected layer (64 -> 32)\n",
        "        self.fc2 = nn.Linear(32, nclass)  # Second fully connected layer (32 -> nclass)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        # x.shape = [max_node, features]\n",
        "        # adj.shape = [max_node, max_node]\n",
        "\n",
        "        # First GCN layer with ReLU activation and dropout\n",
        "        x = F.relu(self.gc1(x, adj))  # x.shape = [num_nodes, 32]\n",
        "        x = F.dropout(x, self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Second GCN layer with ReLU activation and dropout\n",
        "        x = F.relu(self.gc2(x, adj))  # x.shape = [num_nodes, 48]\n",
        "        x = F.dropout(x, self.dropout, training=self.training)  # Apply dropout\n",
        "\n",
        "        # Third GCN layer with ReLU activation\n",
        "        x = F.relu(self.gc3(x, adj))  # x.shape = [num_nodes, 64]\n",
        "\n",
        "        # Aggregate all node features by taking the mean of all nodes\n",
        "        y = torch.mean(x, 0)  # y.shape = [64], aggregate using mean over all nodes\n",
        "\n",
        "        # Apply fully connected layers for final classification\n",
        "        y = F.relu(self.fc1(y))  # First fully connected layer with ReLU activation, y.shape = [32]\n",
        "        y = F.dropout(y, self.dropout, training=self.training)  # Apply dropout\n",
        "        y = F.softmax(self.fc2(y), dim=0)  # Second fully connected layer with softmax activation, y.shape = [nclass]\n",
        "\n",
        "        return y\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Random input features of 29 nodes, each with 7 features\n",
        "    input = torch.rand(29, 7)\n",
        "    # Random adjacency matrix of size 29x29\n",
        "    adj = torch.rand(29, 29)\n",
        "\n",
        "    # Initialize the GCN model with 7 input features, 2 output classes, and a dropout rate of 0.1\n",
        "    model = GCN(nfeat=7,  # nfeat = 7\n",
        "                nclass=2,  # nclass = 2\n",
        "                dropout=0.1)\n",
        "\n",
        "    # Forward pass through the model\n",
        "    output = model(input, adj)\n",
        "    print(output.size())  # Output size should be [nclass], which is [2] in this case\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGQ-uM_kp2qX",
        "outputId": "c61532a5-bc87-4325-f0ff-c0bb18a9d9c5",
        "cellView": "form"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset reshaping for training\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def load_dataset_and_split(train_percent=0.7, val_percent=0.15):\n",
        "    # Prepare the output tensors\n",
        "    num_graphs = len(dataset)\n",
        "    max_nodes = 29  # Given that 29 is the maximum number of nodes in a single graph\n",
        "    num_features = 7\n",
        "\n",
        "    # Initialize the lists to hold the reshaped data\n",
        "    adj_list = torch.zeros((num_graphs, max_nodes, max_nodes))  # [188, 29, 29]\n",
        "    features_list = torch.zeros((num_graphs, max_nodes, num_features))  # [188, 29, 7]\n",
        "    graph_labels = torch.zeros(num_graphs, dtype=torch.long)  # [188]\n",
        "\n",
        "    # Iterate over each graph in the dataset\n",
        "    for i, data in enumerate(dataset):\n",
        "        # Number of nodes in the current graph\n",
        "        num_nodes = data.num_nodes\n",
        "\n",
        "        # Extract the node feature matrix x and store it in features_list\n",
        "        features = data.x  # Shape: [num_nodes, num_features]\n",
        "        features_list[i, :num_nodes, :] = features  # Padding remaining nodes with zeros\n",
        "\n",
        "        # Create adjacency matrix from edge index and add self-loops\n",
        "        adj = to_dense_adj(data.edge_index, max_num_nodes=max_nodes)[0]  # Convert edge index to dense adjacency matrix\n",
        "        adj = adj + torch.eye(max_nodes)  # Add self-loops by adding an identity matrix\n",
        "        adj_list[i] = adj\n",
        "\n",
        "        # Store the graph label\n",
        "        graph_labels[i] = data.y\n",
        "\n",
        "    # Create train-val-test split indices\n",
        "    num_train = int(train_percent * num_graphs)  # 70% of the data for training\n",
        "    num_val = int(val_percent * num_graphs)  # 15% of the data for validation\n",
        "    num_test = num_graphs - num_train - num_val  # Remaining 15% for testing\n",
        "\n",
        "    # Generate shuffled indices\n",
        "    indices = torch.randperm(num_graphs)\n",
        "\n",
        "    # Assign indices to each split\n",
        "    idx_train = indices[:num_train]\n",
        "    idx_val = indices[num_train:num_train + num_val]\n",
        "    idx_test = indices[num_train + num_val:]\n",
        "\n",
        "    # Print the shapes to confirm\n",
        "    print('adj_list:', adj_list.shape)  # Should be [188, 29, 29]\n",
        "    print('features_list:', features_list.shape)  # Should be [188, 29, 7]\n",
        "    print('graph_labels:', graph_labels.shape)  # Should be [188]\n",
        "    print('idx_train:', idx_train.shape)  # Should be [70% of 188]\n",
        "    print('idx_val:', idx_val.shape)  # Should be [15% of 188]\n",
        "    print('idx_test:', idx_test.shape)  # Should be [15% of 188]\n",
        "\n",
        "    return adj_list, features_list, graph_labels, idx_train, idx_val, idx_test"
      ],
      "metadata": {
        "cellView": "form",
        "id": "aZGaCZEIbeZ8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training the GCN\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_path = 'model/gcn_first.pth'\n",
        "\n",
        "epochs = 1000\n",
        "seed = 42\n",
        "lr = 0.001\n",
        "dropout = 0.1\n",
        "weight_decay = 5e-4\n",
        "\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "\n",
        "\n",
        "class EarlyStopping():\n",
        "    def __init__(self, patience=10, min_loss=0.5, hit_min_before_stopping=False):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.hit_min_before_stopping = hit_min_before_stopping\n",
        "        if hit_min_before_stopping:\n",
        "            self.min_loss = min_loss\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "\n",
        "    def __call__(self, loss):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = loss\n",
        "        elif loss > self.best_loss:\n",
        "            self.counter += 1\n",
        "            if self.counter > self.patience:\n",
        "                if self.hit_min_before_stopping == True and loss > self.min_loss:\n",
        "                    print(\"Cannot hit mean loss, will continue\")\n",
        "                    self.counter -= self.patience\n",
        "                else:\n",
        "                    self.early_stop = True\n",
        "        else:\n",
        "            self.best_loss = loss\n",
        "            counter = 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # adj_list: [188, 29, 29]\n",
        "    # features_list: [188, 29, 7]\n",
        "    # graph_labels: [188]\n",
        "    adj_list, features_list, graph_labels, idx_train, idx_val, idx_test = load_dataset_and_split()\n",
        "    idx_train = torch.cat([idx_train, idx_val, idx_test])\n",
        "\n",
        "    model = GCN(nfeat=features_list[0].shape[1], # nfeat = 7\n",
        "                nclass=graph_labels.max().item() + 1, # nclass = 2\n",
        "                dropout=dropout)\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "    model.cuda()\n",
        "    features_list = features_list.cuda()\n",
        "    adj_list = adj_list.cuda()\n",
        "    graph_labels = graph_labels.cuda()\n",
        "    idx_train = idx_train.cuda()\n",
        "    idx_val = idx_val.cuda()\n",
        "    idx_test = idx_test.cuda()\n",
        "\n",
        "    # 训练模型\n",
        "    early_stopping = EarlyStopping(10, hit_min_before_stopping=True)\n",
        "    t_total = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # # Split\n",
        "        outputs = []\n",
        "        for i in idx_train:\n",
        "            output = model(features_list[i], adj_list[i])\n",
        "            output = output.unsqueeze(0)\n",
        "            outputs.append(output)\n",
        "        output = torch.cat(outputs, dim=0)\n",
        "\n",
        "\n",
        "        loss_train = F.cross_entropy(output, graph_labels[idx_train])\n",
        "        acc_train = accuracy(output, graph_labels[idx_train])\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        outputs = []\n",
        "        for i in idx_val:\n",
        "            output = model(features_list[i], adj_list[i])\n",
        "            output = output.unsqueeze(0)\n",
        "            outputs.append(output)\n",
        "        output = torch.cat(outputs, dim=0)\n",
        "        loss_val = F.cross_entropy(output, graph_labels[idx_val])\n",
        "        acc_val = accuracy(output, graph_labels[idx_val])\n",
        "\n",
        "        print('Epoch: {:04d}'.format(epoch + 1),\n",
        "              'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "              'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "              'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "              'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "              'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "        print(loss_val)\n",
        "        early_stopping(loss_val)\n",
        "        if early_stopping.early_stop == True:\n",
        "            break\n",
        "\n",
        "    print(\"Optimization Finished!\")\n",
        "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
        "\n",
        "    torch.save(model.state_dict(), model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9591j-ct0L2",
        "outputId": "6f992936-11c3-4b83-eab0-6e5e51c963ab",
        "cellView": "form"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adj_list: torch.Size([188, 29, 29])\n",
            "features_list: torch.Size([188, 29, 7])\n",
            "graph_labels: torch.Size([188])\n",
            "idx_train: torch.Size([131])\n",
            "idx_val: torch.Size([28])\n",
            "idx_test: torch.Size([29])\n",
            "Epoch: 0001 loss_train: 0.6929 acc_train: 0.5585 loss_val: 0.6883 acc_val: 0.6071 time: 0.2970s\n",
            "tensor(0.6883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0002 loss_train: 0.6860 acc_train: 0.6596 loss_val: 0.6837 acc_val: 0.6071 time: 0.3083s\n",
            "tensor(0.6837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0003 loss_train: 0.6808 acc_train: 0.6649 loss_val: 0.6791 acc_val: 0.6071 time: 0.3228s\n",
            "tensor(0.6791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0004 loss_train: 0.6750 acc_train: 0.6649 loss_val: 0.6746 acc_val: 0.6071 time: 0.2964s\n",
            "tensor(0.6746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0005 loss_train: 0.6693 acc_train: 0.6649 loss_val: 0.6705 acc_val: 0.6071 time: 0.3388s\n",
            "tensor(0.6705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0006 loss_train: 0.6643 acc_train: 0.6649 loss_val: 0.6665 acc_val: 0.6071 time: 0.4527s\n",
            "tensor(0.6665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0007 loss_train: 0.6583 acc_train: 0.6649 loss_val: 0.6624 acc_val: 0.6071 time: 0.4118s\n",
            "tensor(0.6624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0008 loss_train: 0.6541 acc_train: 0.6649 loss_val: 0.6580 acc_val: 0.6071 time: 0.3867s\n",
            "tensor(0.6580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0009 loss_train: 0.6479 acc_train: 0.6649 loss_val: 0.6536 acc_val: 0.6071 time: 0.4419s\n",
            "tensor(0.6536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0010 loss_train: 0.6423 acc_train: 0.6649 loss_val: 0.6493 acc_val: 0.6071 time: 0.4667s\n",
            "tensor(0.6493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0011 loss_train: 0.6366 acc_train: 0.6649 loss_val: 0.6453 acc_val: 0.6071 time: 0.4556s\n",
            "tensor(0.6453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0012 loss_train: 0.6330 acc_train: 0.6649 loss_val: 0.6414 acc_val: 0.6071 time: 0.4671s\n",
            "tensor(0.6414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0013 loss_train: 0.6285 acc_train: 0.6649 loss_val: 0.6376 acc_val: 0.6071 time: 0.2943s\n",
            "tensor(0.6376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0014 loss_train: 0.6215 acc_train: 0.6649 loss_val: 0.6342 acc_val: 0.6071 time: 0.3196s\n",
            "tensor(0.6342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0015 loss_train: 0.6183 acc_train: 0.6649 loss_val: 0.6311 acc_val: 0.6071 time: 0.3007s\n",
            "tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0016 loss_train: 0.6159 acc_train: 0.6649 loss_val: 0.6285 acc_val: 0.6071 time: 0.3142s\n",
            "tensor(0.6285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0017 loss_train: 0.6098 acc_train: 0.6649 loss_val: 0.6265 acc_val: 0.6071 time: 0.3038s\n",
            "tensor(0.6265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0018 loss_train: 0.6041 acc_train: 0.6649 loss_val: 0.6252 acc_val: 0.6071 time: 0.3088s\n",
            "tensor(0.6252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0019 loss_train: 0.5997 acc_train: 0.6649 loss_val: 0.6245 acc_val: 0.6071 time: 0.2985s\n",
            "tensor(0.6245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0020 loss_train: 0.5990 acc_train: 0.6649 loss_val: 0.6246 acc_val: 0.6071 time: 0.2977s\n",
            "tensor(0.6246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0021 loss_train: 0.5992 acc_train: 0.6649 loss_val: 0.6252 acc_val: 0.6071 time: 0.3073s\n",
            "tensor(0.6252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0022 loss_train: 0.5972 acc_train: 0.6649 loss_val: 0.6263 acc_val: 0.6071 time: 0.3008s\n",
            "tensor(0.6263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0023 loss_train: 0.5995 acc_train: 0.6649 loss_val: 0.6277 acc_val: 0.6071 time: 0.2967s\n",
            "tensor(0.6277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0024 loss_train: 0.5964 acc_train: 0.6649 loss_val: 0.6291 acc_val: 0.6071 time: 0.3131s\n",
            "tensor(0.6291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0025 loss_train: 0.5981 acc_train: 0.6649 loss_val: 0.6303 acc_val: 0.6071 time: 0.2989s\n",
            "tensor(0.6303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0026 loss_train: 0.5955 acc_train: 0.6649 loss_val: 0.6313 acc_val: 0.6071 time: 0.3088s\n",
            "tensor(0.6313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0027 loss_train: 0.5974 acc_train: 0.6649 loss_val: 0.6319 acc_val: 0.6071 time: 0.3087s\n",
            "tensor(0.6319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0028 loss_train: 0.6014 acc_train: 0.6649 loss_val: 0.6321 acc_val: 0.6071 time: 0.3039s\n",
            "tensor(0.6321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0029 loss_train: 0.5981 acc_train: 0.6649 loss_val: 0.6318 acc_val: 0.6071 time: 0.2950s\n",
            "tensor(0.6318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0030 loss_train: 0.5986 acc_train: 0.6649 loss_val: 0.6311 acc_val: 0.6071 time: 0.2990s\n",
            "tensor(0.6311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Cannot hit mean loss, will continue\n",
            "Epoch: 0031 loss_train: 0.5947 acc_train: 0.6649 loss_val: 0.6299 acc_val: 0.6071 time: 0.3117s\n",
            "tensor(0.6299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0032 loss_train: 0.5999 acc_train: 0.6649 loss_val: 0.6285 acc_val: 0.6071 time: 0.3100s\n",
            "tensor(0.6285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0033 loss_train: 0.5992 acc_train: 0.6649 loss_val: 0.6267 acc_val: 0.6071 time: 0.2976s\n",
            "tensor(0.6267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0034 loss_train: 0.5960 acc_train: 0.6649 loss_val: 0.6249 acc_val: 0.6071 time: 0.3153s\n",
            "tensor(0.6249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0035 loss_train: 0.5960 acc_train: 0.6649 loss_val: 0.6230 acc_val: 0.6071 time: 0.3025s\n",
            "tensor(0.6230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0036 loss_train: 0.5952 acc_train: 0.6649 loss_val: 0.6211 acc_val: 0.6071 time: 0.2970s\n",
            "tensor(0.6211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0037 loss_train: 0.5933 acc_train: 0.6649 loss_val: 0.6192 acc_val: 0.6071 time: 0.3098s\n",
            "tensor(0.6192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0038 loss_train: 0.5951 acc_train: 0.6649 loss_val: 0.6175 acc_val: 0.6071 time: 0.3071s\n",
            "tensor(0.6175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0039 loss_train: 0.5948 acc_train: 0.6649 loss_val: 0.6160 acc_val: 0.6071 time: 0.2963s\n",
            "tensor(0.6160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0040 loss_train: 0.5942 acc_train: 0.6649 loss_val: 0.6146 acc_val: 0.6071 time: 0.2923s\n",
            "tensor(0.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0041 loss_train: 0.5949 acc_train: 0.6649 loss_val: 0.6135 acc_val: 0.6071 time: 0.3147s\n",
            "tensor(0.6135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0042 loss_train: 0.5900 acc_train: 0.6649 loss_val: 0.6124 acc_val: 0.6071 time: 0.2996s\n",
            "tensor(0.6124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0043 loss_train: 0.5891 acc_train: 0.6649 loss_val: 0.6115 acc_val: 0.6071 time: 0.2917s\n",
            "tensor(0.6115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0044 loss_train: 0.5914 acc_train: 0.6649 loss_val: 0.6105 acc_val: 0.6071 time: 0.3139s\n",
            "tensor(0.6105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0045 loss_train: 0.5925 acc_train: 0.6649 loss_val: 0.6097 acc_val: 0.6071 time: 0.4072s\n",
            "tensor(0.6097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0046 loss_train: 0.5877 acc_train: 0.6649 loss_val: 0.6088 acc_val: 0.6071 time: 0.4005s\n",
            "tensor(0.6088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0047 loss_train: 0.5883 acc_train: 0.6649 loss_val: 0.6080 acc_val: 0.6071 time: 0.4341s\n",
            "tensor(0.6080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0048 loss_train: 0.5890 acc_train: 0.6649 loss_val: 0.6071 acc_val: 0.6071 time: 0.3951s\n",
            "tensor(0.6071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0049 loss_train: 0.5892 acc_train: 0.6649 loss_val: 0.6063 acc_val: 0.6071 time: 0.4705s\n",
            "tensor(0.6063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0050 loss_train: 0.5853 acc_train: 0.6649 loss_val: 0.6055 acc_val: 0.6071 time: 0.4808s\n",
            "tensor(0.6055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0051 loss_train: 0.5838 acc_train: 0.6649 loss_val: 0.6046 acc_val: 0.6071 time: 0.4793s\n",
            "tensor(0.6046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0052 loss_train: 0.5844 acc_train: 0.6649 loss_val: 0.6037 acc_val: 0.6071 time: 0.2940s\n",
            "tensor(0.6037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0053 loss_train: 0.5815 acc_train: 0.6649 loss_val: 0.6027 acc_val: 0.6071 time: 0.2921s\n",
            "tensor(0.6027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0054 loss_train: 0.5787 acc_train: 0.6649 loss_val: 0.6014 acc_val: 0.6071 time: 0.3065s\n",
            "tensor(0.6014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0055 loss_train: 0.5848 acc_train: 0.6649 loss_val: 0.6000 acc_val: 0.6071 time: 0.3128s\n",
            "tensor(0.6000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0056 loss_train: 0.5800 acc_train: 0.6649 loss_val: 0.5984 acc_val: 0.6071 time: 0.2892s\n",
            "tensor(0.5984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0057 loss_train: 0.5807 acc_train: 0.6649 loss_val: 0.5967 acc_val: 0.6071 time: 0.2916s\n",
            "tensor(0.5967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0058 loss_train: 0.5783 acc_train: 0.6649 loss_val: 0.5949 acc_val: 0.6071 time: 0.3204s\n",
            "tensor(0.5949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0059 loss_train: 0.5741 acc_train: 0.6649 loss_val: 0.5929 acc_val: 0.6071 time: 0.2857s\n",
            "tensor(0.5929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0060 loss_train: 0.5773 acc_train: 0.6649 loss_val: 0.5909 acc_val: 0.6071 time: 0.3032s\n",
            "tensor(0.5909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0061 loss_train: 0.5764 acc_train: 0.6649 loss_val: 0.5890 acc_val: 0.6071 time: 0.3146s\n",
            "tensor(0.5890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0062 loss_train: 0.5764 acc_train: 0.6649 loss_val: 0.5870 acc_val: 0.6071 time: 0.2950s\n",
            "tensor(0.5870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0063 loss_train: 0.5746 acc_train: 0.6649 loss_val: 0.5850 acc_val: 0.6071 time: 0.3040s\n",
            "tensor(0.5850, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0064 loss_train: 0.5688 acc_train: 0.6649 loss_val: 0.5830 acc_val: 0.6071 time: 0.3053s\n",
            "tensor(0.5830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0065 loss_train: 0.5739 acc_train: 0.6649 loss_val: 0.5810 acc_val: 0.6071 time: 0.3043s\n",
            "tensor(0.5810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0066 loss_train: 0.5741 acc_train: 0.6649 loss_val: 0.5789 acc_val: 0.6071 time: 0.2919s\n",
            "tensor(0.5789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0067 loss_train: 0.5658 acc_train: 0.6649 loss_val: 0.5767 acc_val: 0.6071 time: 0.2948s\n",
            "tensor(0.5767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0068 loss_train: 0.5697 acc_train: 0.6649 loss_val: 0.5741 acc_val: 0.6429 time: 0.3150s\n",
            "tensor(0.5741, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0069 loss_train: 0.5658 acc_train: 0.6702 loss_val: 0.5713 acc_val: 0.6429 time: 0.2926s\n",
            "tensor(0.5713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0070 loss_train: 0.5631 acc_train: 0.6702 loss_val: 0.5683 acc_val: 0.6429 time: 0.2885s\n",
            "tensor(0.5683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0071 loss_train: 0.5579 acc_train: 0.6755 loss_val: 0.5653 acc_val: 0.6429 time: 0.3105s\n",
            "tensor(0.5653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0072 loss_train: 0.5621 acc_train: 0.6702 loss_val: 0.5625 acc_val: 0.6786 time: 0.3007s\n",
            "tensor(0.5625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0073 loss_train: 0.5560 acc_train: 0.6915 loss_val: 0.5596 acc_val: 0.7500 time: 0.2958s\n",
            "tensor(0.5596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0074 loss_train: 0.5522 acc_train: 0.6968 loss_val: 0.5570 acc_val: 0.7857 time: 0.3056s\n",
            "tensor(0.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0075 loss_train: 0.5477 acc_train: 0.7234 loss_val: 0.5545 acc_val: 0.7857 time: 0.3141s\n",
            "tensor(0.5545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0076 loss_train: 0.5549 acc_train: 0.7074 loss_val: 0.5522 acc_val: 0.7857 time: 0.2881s\n",
            "tensor(0.5522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0077 loss_train: 0.5502 acc_train: 0.7340 loss_val: 0.5500 acc_val: 0.7857 time: 0.3070s\n",
            "tensor(0.5500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0078 loss_train: 0.5421 acc_train: 0.7394 loss_val: 0.5479 acc_val: 0.7500 time: 0.3279s\n",
            "tensor(0.5479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0079 loss_train: 0.5453 acc_train: 0.7553 loss_val: 0.5460 acc_val: 0.8214 time: 0.2989s\n",
            "tensor(0.5460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0080 loss_train: 0.5406 acc_train: 0.7606 loss_val: 0.5446 acc_val: 0.8214 time: 0.2922s\n",
            "tensor(0.5446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0081 loss_train: 0.5405 acc_train: 0.7713 loss_val: 0.5430 acc_val: 0.8214 time: 0.3317s\n",
            "tensor(0.5430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0082 loss_train: 0.5369 acc_train: 0.7872 loss_val: 0.5413 acc_val: 0.8214 time: 0.2918s\n",
            "tensor(0.5413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0083 loss_train: 0.5377 acc_train: 0.7872 loss_val: 0.5395 acc_val: 0.8214 time: 0.3003s\n",
            "tensor(0.5395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0084 loss_train: 0.5321 acc_train: 0.7926 loss_val: 0.5375 acc_val: 0.8214 time: 0.3871s\n",
            "tensor(0.5375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0085 loss_train: 0.5322 acc_train: 0.7979 loss_val: 0.5359 acc_val: 0.8571 time: 0.4169s\n",
            "tensor(0.5359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0086 loss_train: 0.5295 acc_train: 0.7819 loss_val: 0.5342 acc_val: 0.8571 time: 0.3879s\n",
            "tensor(0.5342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0087 loss_train: 0.5235 acc_train: 0.8032 loss_val: 0.5331 acc_val: 0.8571 time: 0.3945s\n",
            "tensor(0.5331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0088 loss_train: 0.5265 acc_train: 0.8032 loss_val: 0.5316 acc_val: 0.8214 time: 0.4477s\n",
            "tensor(0.5316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0089 loss_train: 0.5279 acc_train: 0.7819 loss_val: 0.5291 acc_val: 0.8571 time: 0.4911s\n",
            "tensor(0.5291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0090 loss_train: 0.5227 acc_train: 0.8032 loss_val: 0.5263 acc_val: 0.8571 time: 0.4660s\n",
            "tensor(0.5263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0091 loss_train: 0.5243 acc_train: 0.7926 loss_val: 0.5247 acc_val: 0.8571 time: 0.3213s\n",
            "tensor(0.5247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0092 loss_train: 0.5237 acc_train: 0.8085 loss_val: 0.5235 acc_val: 0.8214 time: 0.3097s\n",
            "tensor(0.5235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0093 loss_train: 0.5150 acc_train: 0.8085 loss_val: 0.5216 acc_val: 0.8571 time: 0.2950s\n",
            "tensor(0.5216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0094 loss_train: 0.5174 acc_train: 0.8085 loss_val: 0.5187 acc_val: 0.8571 time: 0.3418s\n",
            "tensor(0.5187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0095 loss_train: 0.5113 acc_train: 0.8032 loss_val: 0.5163 acc_val: 0.8571 time: 0.3100s\n",
            "tensor(0.5163, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0096 loss_train: 0.5147 acc_train: 0.8032 loss_val: 0.5143 acc_val: 0.8571 time: 0.2926s\n",
            "tensor(0.5143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0097 loss_train: 0.5133 acc_train: 0.8085 loss_val: 0.5127 acc_val: 0.8571 time: 0.3064s\n",
            "tensor(0.5127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0098 loss_train: 0.5129 acc_train: 0.8032 loss_val: 0.5093 acc_val: 0.8571 time: 0.2973s\n",
            "tensor(0.5093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0099 loss_train: 0.5113 acc_train: 0.7926 loss_val: 0.5061 acc_val: 0.8571 time: 0.2995s\n",
            "tensor(0.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0100 loss_train: 0.5091 acc_train: 0.8138 loss_val: 0.5044 acc_val: 0.8571 time: 0.3047s\n",
            "tensor(0.5044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0101 loss_train: 0.5121 acc_train: 0.7979 loss_val: 0.5040 acc_val: 0.8571 time: 0.2890s\n",
            "tensor(0.5040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0102 loss_train: 0.5122 acc_train: 0.8085 loss_val: 0.5025 acc_val: 0.8214 time: 0.3036s\n",
            "tensor(0.5025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0103 loss_train: 0.5112 acc_train: 0.8085 loss_val: 0.4983 acc_val: 0.8571 time: 0.2969s\n",
            "tensor(0.4983, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0104 loss_train: 0.4990 acc_train: 0.8191 loss_val: 0.4964 acc_val: 0.8571 time: 0.3107s\n",
            "tensor(0.4964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0105 loss_train: 0.5011 acc_train: 0.8298 loss_val: 0.4947 acc_val: 0.8571 time: 0.3014s\n",
            "tensor(0.4947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0106 loss_train: 0.5010 acc_train: 0.8351 loss_val: 0.4938 acc_val: 0.8571 time: 0.3088s\n",
            "tensor(0.4938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0107 loss_train: 0.4975 acc_train: 0.8298 loss_val: 0.4924 acc_val: 0.8214 time: 0.3023s\n",
            "tensor(0.4924, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0108 loss_train: 0.4858 acc_train: 0.8298 loss_val: 0.4905 acc_val: 0.8214 time: 0.3173s\n",
            "tensor(0.4905, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0109 loss_train: 0.4996 acc_train: 0.8085 loss_val: 0.4872 acc_val: 0.8571 time: 0.3105s\n",
            "tensor(0.4872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0110 loss_train: 0.5017 acc_train: 0.8191 loss_val: 0.4863 acc_val: 0.8571 time: 0.3088s\n",
            "tensor(0.4863, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0111 loss_train: 0.5019 acc_train: 0.8245 loss_val: 0.4851 acc_val: 0.8571 time: 0.3059s\n",
            "tensor(0.4851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0112 loss_train: 0.4950 acc_train: 0.8298 loss_val: 0.4823 acc_val: 0.8571 time: 0.3109s\n",
            "tensor(0.4823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0113 loss_train: 0.4830 acc_train: 0.8404 loss_val: 0.4792 acc_val: 0.8571 time: 0.3030s\n",
            "tensor(0.4792, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0114 loss_train: 0.4893 acc_train: 0.8351 loss_val: 0.4779 acc_val: 0.7857 time: 0.3080s\n",
            "tensor(0.4779, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0115 loss_train: 0.4981 acc_train: 0.8085 loss_val: 0.4751 acc_val: 0.8571 time: 0.3055s\n",
            "tensor(0.4751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0116 loss_train: 0.4946 acc_train: 0.8138 loss_val: 0.4767 acc_val: 0.8571 time: 0.2899s\n",
            "tensor(0.4767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0117 loss_train: 0.4894 acc_train: 0.8138 loss_val: 0.4762 acc_val: 0.8571 time: 0.3076s\n",
            "tensor(0.4762, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0118 loss_train: 0.4746 acc_train: 0.8351 loss_val: 0.4704 acc_val: 0.8571 time: 0.2942s\n",
            "tensor(0.4704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0119 loss_train: 0.4880 acc_train: 0.8298 loss_val: 0.4661 acc_val: 0.8571 time: 0.3151s\n",
            "tensor(0.4661, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0120 loss_train: 0.4746 acc_train: 0.8351 loss_val: 0.4628 acc_val: 0.8571 time: 0.3053s\n",
            "tensor(0.4628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0121 loss_train: 0.4969 acc_train: 0.8085 loss_val: 0.4648 acc_val: 0.8571 time: 0.3048s\n",
            "tensor(0.4648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0122 loss_train: 0.4767 acc_train: 0.8404 loss_val: 0.4700 acc_val: 0.8571 time: 0.3056s\n",
            "tensor(0.4700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0123 loss_train: 0.4837 acc_train: 0.8351 loss_val: 0.4705 acc_val: 0.8571 time: 0.3868s\n",
            "tensor(0.4705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0124 loss_train: 0.4791 acc_train: 0.8351 loss_val: 0.4623 acc_val: 0.8571 time: 0.4147s\n",
            "tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0125 loss_train: 0.4701 acc_train: 0.8617 loss_val: 0.4534 acc_val: 0.8571 time: 0.4061s\n",
            "tensor(0.4534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0126 loss_train: 0.4752 acc_train: 0.8617 loss_val: 0.4488 acc_val: 0.8571 time: 0.7367s\n",
            "tensor(0.4488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0127 loss_train: 0.4756 acc_train: 0.8298 loss_val: 0.4508 acc_val: 0.8571 time: 0.4776s\n",
            "tensor(0.4508, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Optimization Finished!\n",
            "Total time elapsed: 42.8517s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRAPH GENERATOR"
      ],
      "metadata": {
        "id": "UcFDzaHOpvxe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OlikZDjJpDyU"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "rollout = 10\n",
        "MAX_NUM_NODES = 28 # for mutag\n",
        "random.seed(200)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, model_path: str, C: list, node_feature_dim: int ,num_class = 2, c=0, hyp1=1, hyp2=2, start=None, nfeat=7, dropout=0.1):\n",
        "        \"\"\"\n",
        "        :param C: Candidate set of nodes (list)\n",
        "        :param start: Starting node (defaults to randomised node)\n",
        "        \"\"\"\n",
        "        super(Generator, self).__init__()\n",
        "        self.nfeat = nfeat\n",
        "        self.dropout = dropout\n",
        "        self.c = c # c为要指定生成类别c的图\n",
        "\n",
        "        self.fc = nn.Linear(nfeat, 8)\n",
        "        self.gc1 = GraphConvolution(8, 16)\n",
        "        self.gc2 = GraphConvolution(16, 24)\n",
        "        self.gc3 = GraphConvolution(24, 32)\n",
        "\n",
        "        # MLP1\n",
        "        # 2 FC layers with hidden dimension 16\n",
        "        self.mlp1 = nn.Sequential(nn.Linear(32, 16), nn.Linear(16, 1))\n",
        "\n",
        "        # MLP2\n",
        "        # 2 FC layers with hidden dimension 24\n",
        "        self.mlp2 = nn.Sequential(nn.Linear(64, 24), nn.Linear(24, 1))\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.hyp1 = hyp1\n",
        "        self.hyp2 = hyp2\n",
        "        self.candidate_set = C\n",
        "\n",
        "        # Default starting node (if any)\n",
        "        if start != None:\n",
        "            self.start = start\n",
        "            self.random_start = False\n",
        "        else:\n",
        "            self.start = random.choice(np.arange(0, len(self.candidate_set)))\n",
        "            self.random_start = True\n",
        "\n",
        "        # Load GCN for calculating reward\n",
        "        self.model = GCN(nfeat=node_feature_dim,\n",
        "                         nclass=num_class,\n",
        "                         dropout=dropout)\n",
        "\n",
        "        self.model.load_state_dict(torch.load(model_path))\n",
        "        for param in self.model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.reset_graph()\n",
        "\n",
        "    def reset_graph(self):\n",
        "        \"\"\"\n",
        "        Reset g.G to default graph with only start node， 生成一个只有1个结点的图\n",
        "        \"\"\"\n",
        "        if self.random_start == True:\n",
        "            self.start = random.choice(np.arange(0, len(self.candidate_set)))\n",
        "\n",
        "        # 初始图除了第1个结点全被mask，这里由于邻接矩阵的边长为MAX_NUM_NODES + len(self.candidate_set)，所以mask的不仅为候选集结点，还有图中的所以虚结点\n",
        "        mask_start = torch.BoolTensor(\n",
        "            [False if i == 0 else True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\n",
        "\n",
        "        adj = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), MAX_NUM_NODES + len(self.candidate_set)),\n",
        "                          dtype=torch.float32)   # 这里adj shape为 [MAX_NUM_NODES + len(self.candidate_set), MAX_NUM_NODES + len(self.candidate_set)] 中间可能有空结点\n",
        "\n",
        "        feat = torch.zeros((MAX_NUM_NODES + len(self.candidate_set), len(self.candidate_set)), dtype=torch.float32)\n",
        "        feat[0, self.start] = 1\n",
        "        feat[np.arange(-len(self.candidate_set), 0), np.arange(0, len(self.candidate_set))] = 1\n",
        "\n",
        "        degrees = torch.zeros(MAX_NUM_NODES)\n",
        "\n",
        "        self.G = {'adj': adj, 'feat': feat, 'degrees': degrees, 'num_nodes': 1, 'mask_start': mask_start}\n",
        "\n",
        "    ## 计算Gt->Gt+1\n",
        "    def forward(self, G_in):\n",
        "        ## G_in为 Gt\n",
        "        G = copy.deepcopy(G_in)\n",
        "\n",
        "        x = G['feat'].detach().clone() # Gt的特征矩阵\n",
        "        adj = G['adj'].detach().clone() # Gt的邻接矩阵\n",
        "\n",
        "        ## 对应 X = GCNs(Gt​,C)\n",
        "        x = F.relu6(self.fc(x))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu6(self.gc1(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu6(self.gc2(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.relu6(self.gc3(x, adj))\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "\n",
        "        ## pt,start​=Softmax(MLPs(X))\n",
        "        p_start = self.mlp1(x)\n",
        "        p_start = p_start.masked_fill(G['mask_start'].unsqueeze(1), 0)\n",
        "        p_start = F.softmax(p_start, dim=0)\n",
        "        a_start_idx = torch.argmax(p_start.masked_fill(G['mask_start'].unsqueeze(1), -1))\n",
        "\n",
        "        ## pt,end​=Softmax(MLPs([X,x^start​))\n",
        "        # broadcast\n",
        "        x1, x2 = torch.broadcast_tensors(x, x[a_start_idx])\n",
        "        x = torch.cat((x1, x2), 1)  # cat increases dim from 32 to 64\n",
        "\n",
        "        # 计算maskt,end，除了候选集和Gt结点中未被选为初始结点的结点之外，其它均被mask\n",
        "        mask_end = torch.BoolTensor([True for i in range(MAX_NUM_NODES + len(self.candidate_set))])\n",
        "        mask_end[MAX_NUM_NODES:] = False\n",
        "        mask_end[:G['num_nodes']] = False\n",
        "        mask_end[a_start_idx] = True\n",
        "\n",
        "        p_end = self.mlp2(x)\n",
        "        p_end = p_end.masked_fill(mask_end.unsqueeze(1), 0)\n",
        "        p_end = F.softmax(p_end, dim=0)\n",
        "        a_end_idx = torch.argmax(p_end.masked_fill(mask_end.unsqueeze(1), -1))\n",
        "\n",
        "        # Return new G\n",
        "        # If a_end_idx is not masked, node exists in graph, no new node added\n",
        "        if G['mask_start'][a_end_idx] == False:\n",
        "            G['adj'][a_end_idx][a_start_idx] += 1\n",
        "            G['adj'][a_start_idx][a_end_idx] += 1\n",
        "\n",
        "            # Update degrees\n",
        "            G['degrees'][a_start_idx] += 1\n",
        "            G['degrees'][G['num_nodes']] += 1\n",
        "        else:\n",
        "            # Add node\n",
        "            G['feat'][G['num_nodes']] = G['feat'][a_end_idx]\n",
        "            # Add edge\n",
        "            G['adj'][G['num_nodes']][a_start_idx] += 1\n",
        "            G['adj'][a_start_idx][G['num_nodes']] += 1\n",
        "            # Update degrees\n",
        "            G['degrees'][a_start_idx] += 1\n",
        "            G['degrees'][G['num_nodes']] += 1\n",
        "\n",
        "            # Update start mask\n",
        "            G_mask_start_copy = G['mask_start'].detach().clone()\n",
        "            G_mask_start_copy[G['num_nodes']] = False\n",
        "            G['mask_start'] = G_mask_start_copy\n",
        "\n",
        "            G['num_nodes'] += 1\n",
        "\n",
        "        return p_start, a_start_idx, p_end, a_end_idx, G\n",
        "\n",
        "\n",
        "    ### reward函数\n",
        "    def calculate_reward(self, G_t_1):\n",
        "        \"\"\"\n",
        "        Rtr     Calculated from graph rules to encourage generated graphs to be valid\n",
        "                1. Only one edge to be added between any two nodes\n",
        "                2. Generated graph cannot contain more nodes than predefined maximum node number\n",
        "                3. (For chemical) Degree cannot exceed valency\n",
        "                If generated graph violates graph rule, Rtr = -1\n",
        "\n",
        "        Rtf     Feedback from trained model\n",
        "        \"\"\"\n",
        "\n",
        "        rtr = self.check_graph_rules(G_t_1)\n",
        "\n",
        "        rtf = self.calculate_reward_feedback(G_t_1)\n",
        "        rtf_sum = 0\n",
        "        for m in range(rollout):\n",
        "            p_start, a_start, p_end, a_end, G_t_1 = self.forward(G_t_1)\n",
        "            rtf_sum += self.calculate_reward_feedback(G_t_1)\n",
        "        rtf = rtf + rtf_sum * self.hyp1 / rollout\n",
        "\n",
        "        return rtf + self.hyp2 * rtr\n",
        "\n",
        "    def calculate_reward_feedback(self, G_t_1):\n",
        "        \"\"\"\n",
        "        p(f(G_t_1) = c) - 1/l\n",
        "        where l denotes number of possible classes for f\n",
        "        \"\"\"\n",
        "        f = self.model(G_t_1['feat'], G_t_1['adj'])\n",
        "        return f[self.c] - 1 / len(f)\n",
        "\n",
        "\n",
        "    ## graph rules\n",
        "    def check_graph_rules(self, G_t_1):\n",
        "        \"\"\"\n",
        "        For mutag, node degrees cannot exceed valency\n",
        "        \"\"\"\n",
        "        idx = 0\n",
        "\n",
        "        for d in G_t_1['degrees']:\n",
        "            if d != 0:\n",
        "                node_id = torch.argmax(G_t_1['feat'][idx])  # Eg. [0, 1, 0, 0] -> 1\n",
        "                node = self.candidate_set[node_id]  # Eg ['C.4', 'F.2', 'Br.7'][1] = 'F.2'\n",
        "                max_valency = int(node.split('.')[1])  # Eg. C.4 -> ['C', '4'] -> 4\n",
        "\n",
        "                # If any node degree exceeds its valency, return -1\n",
        "                if max_valency < d:\n",
        "                    return -1\n",
        "\n",
        "        return 0\n",
        "\n",
        "\n",
        "    ## 计算loss\n",
        "    def calculate_loss(self, Rt, p_start, a_start, p_end, a_end, G_t_1):\n",
        "        \"\"\"\n",
        "        Calculated from cross entropy loss (Lce) and reward function (Rt)\n",
        "        where loss = -Rt*(Lce_start + Lce_end)\n",
        "        \"\"\"\n",
        "\n",
        "        Lce_start = F.cross_entropy(torch.reshape(p_start, (1, 35)), a_start.unsqueeze(0))\n",
        "        Lce_end = F.cross_entropy(torch.reshape(p_end, (1, 35)), a_end.unsqueeze(0))\n",
        "\n",
        "        return -Rt * (Lce_start + Lce_end)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CHECK"
      ],
      "metadata": {
        "id": "ClOj0KCGqF7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import torch\n",
        "\n",
        "src_path = '/content/datas/MUTAG_{}'\n",
        "split_train=0.7\n",
        "split_val=0.15\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    nodeidx_features = np.genfromtxt(src_path.format('node_labels.txt'), delimiter=\",\",\n",
        "                                     dtype=np.dtype(int))\n",
        "    node_features = np.zeros((nodeidx_features.shape[0], max(nodeidx_features) + 1))\n",
        "    node_features[np.arange(nodeidx_features.shape[0]), nodeidx_features] = 1\n",
        "\n",
        "\n",
        "    graph_labels = np.genfromtxt(src_path.format('graph_labels.txt'), dtype=np.dtype(int))\n",
        "    graph_labels = encode_onehot(graph_labels)\n",
        "    graph_labels = torch.LongTensor(np.where(graph_labels)[1])\n",
        "\n",
        "\n",
        "    graph_idx = np.genfromtxt(src_path.format('graph_indicator.txt'),dtype=np.dtype(int))\n",
        "    graph_idx = np.array(graph_idx, dtype=np.int32)\n",
        "\n",
        "\n",
        "    edges_unordered = np.genfromtxt(src_path.format('A.txt'), delimiter=\",\",\n",
        "                                    dtype=np.int32)  # (7442,2)\n",
        "\n",
        "    edges_label = np.genfromtxt(src_path.format('edge_labels.txt'), delimiter=\",\",\n",
        "                                dtype=np.int32)\n",
        "\n",
        "    # 邻接矩阵\n",
        "    adj = sp.coo_matrix((edges_label, (edges_unordered[:, 0] - 1, edges_unordered[:, 1] - 1)))\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj) # (3371, 3371)\n",
        "\n",
        "    idx_map = {j: i for i, j in enumerate(graph_idx)} # key, value表示第key个图的起始结点索引号为value\n",
        "    length = len(idx_map.keys())  # 总共有多少个图 , 188\n",
        "    num_nodes = [idx_map[n] - idx_map[n - 1] if n - 1 > 1 else idx_map[n] for n in range(1, length + 1)]  # 一个长度188的list，表示没个图有多少个结点\n",
        "    max_num_nodes = max(num_nodes) # 最大的一个图有多少个结点 实际29\n",
        "    features_list = []\n",
        "    adj_list = []\n",
        "    prev = 0\n",
        "\n",
        "    node_features = normalize(node_features) # (3371, 7)\n",
        "    adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        "    adj = adj.todense()\n",
        "\n",
        "    for n in range(1, length + 1):\n",
        "        # entry为图的特征矩阵X\n",
        "        entry = np.zeros((max_num_nodes, max(nodeidx_features) + 1))\n",
        "        entry[:idx_map[n] - prev] = node_features[prev:idx_map[n]]\n",
        "        entry = torch.FloatTensor(entry)\n",
        "        features_list.append(entry)\n",
        "\n",
        "        # entry为图的邻接矩阵A\n",
        "        entry = np.zeros((max_num_nodes, max_num_nodes))\n",
        "        entry[:idx_map[n] - prev, :idx_map[n] - prev] = adj[prev:idx_map[n], prev:idx_map[n]]\n",
        "        entry = torch.FloatTensor(entry)\n",
        "        adj_list.append(entry)\n",
        "\n",
        "        prev = idx_map[n] # prev为下个图起始结点的索引号\n",
        "\n",
        "    num_total = max(graph_idx)\n",
        "    num_train = int(split_train * num_total)\n",
        "    num_val = int((split_train + split_val) * num_total)\n",
        "\n",
        "    idx_train = range(num_train)\n",
        "    idx_val = range(num_train, num_val)\n",
        "    idx_test = range(num_val, num_total)\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "\n",
        "    print(graph_labels[idx_train])\n",
        "    print(graph_labels[idx_val])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoWXtD_FqHpZ",
        "outputId": "f4e11552-3c04-4f8f-e9ef-28969ee375e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
            "        1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "        0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1])\n",
            "tensor([1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
            "        1, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING GENERATOR"
      ],
      "metadata": {
        "id": "5eXvbB3Vp-2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.01\n",
        "b1 = 0.9\n",
        "b2 = 0.99\n",
        "hyp1 = 1\n",
        "hyp2 = 2\n",
        "max_gen_step = 10  # T = 10\n",
        "\n",
        "candidate_set = ['C.4', 'N.5', 'O.2', 'F.1', 'I.7', 'Cl.7', 'Br.5']  # C.4表明碳原子的度不超过4\n",
        "model_path = 'model/gcn_first.pth'\n",
        "\n",
        "## 训练generator\n",
        "def train_generator(c=0, max_nodes=5):\n",
        "    g.c = c\n",
        "    for i in range(max_gen_step):\n",
        "        optimizer.zero_grad()\n",
        "        G = copy.deepcopy(g.G)\n",
        "        p_start, a_start, p_end, a_end, G = g.forward(G)\n",
        "\n",
        "        Rt = g.calculate_reward(G)\n",
        "        loss = g.calculate_loss(Rt, p_start, a_start, p_end, a_end, G)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if G['num_nodes'] > max_nodes:\n",
        "            g.reset_graph()\n",
        "        elif Rt > 0:\n",
        "            g.G = G\n",
        "\n",
        "\n",
        "## 生成图\n",
        "def generate_graph(c=0, max_nodes=5):\n",
        "    g.c = c\n",
        "    g.reset_graph()\n",
        "\n",
        "    for i in range(max_gen_step):\n",
        "        G = copy.deepcopy(g.G)\n",
        "        p_start, a_start, p_end, a_end, G = g.forward(G)\n",
        "        Rt = g.calculate_reward(G)\n",
        "\n",
        "        if G['num_nodes'] > max_nodes:\n",
        "            return g.G\n",
        "        elif Rt > 0:\n",
        "            g.G = G\n",
        "\n",
        "    return g.G\n",
        "\n",
        "## 画图\n",
        "def display_graph(G):\n",
        "    G_nx = nx.from_numpy_array(np.asmatrix(G['adj'][:G['num_nodes'], :G['num_nodes']].numpy()))\n",
        "    # nx.draw_networkx(G_nx)\n",
        "\n",
        "    layout=nx.spring_layout(G_nx)\n",
        "    nx.draw(G_nx, layout)\n",
        "\n",
        "    coloring=torch.argmax(G['feat'],1)\n",
        "    colors=['b','g','r','c','m','y','k']\n",
        "\n",
        "    for i in range(7):\n",
        "        nx.draw_networkx_nodes(G_nx,pos=layout,nodelist=[x for x in G_nx.nodes() if coloring[x]==i],node_color=colors[i])\n",
        "        nx.draw_networkx_labels(G_nx,pos=layout,labels={x:candidate_set[i].split('.')[0] for x in G_nx.nodes() if coloring[x]==i})\n",
        "    nx.draw_networkx_edges(G_nx,pos=layout,width=list(nx.get_edge_attributes(G_nx,'weight').values()))\n",
        "    nx.draw_networkx_edge_labels(G_nx,pos=layout,edge_labels=nx.get_edge_attributes(G_nx, \"weight\"))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    g = Generator(model_path = model_path, C = candidate_set, node_feature_dim=7 ,c=0, start=0)\n",
        "    optimizer = optim.Adam(g.parameters(), lr=lr, betas=(b1, b2))\n",
        "\n",
        "    for i in range(1, 10):\n",
        "        ## 生成最多分别包括i个结点的图结构\n",
        "        g.reset_graph()\n",
        "        train_generator(c=1, max_nodes=i)\n",
        "        to_display = generate_graph(c=1, max_nodes=i)\n",
        "        display_graph(to_display)\n",
        "        print(g.model(to_display['feat'], to_display['adj']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n15NwMKbqBak",
        "outputId": "89d6e287-837e-49ee-de7c-b76f9ed95d24"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-c93076f51218>:56: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7190, 0.2810])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7186, 0.2814])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7186, 0.2814])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7021, 0.2979])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6807, 0.3193])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7030, 0.2970])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7030, 0.2970])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAM5ElEQVR4nO3dT6hmZR3A8d+rw8zchmTgDojirjZaCSIMgmNtS3RptJCI1GlZK4MMchm2atMi1NXQZmiTlosgSMeKwIRIXZS1agZhLg7WeEcZ5m1xJ/w3c8fuV5sZ389nM9x77jnnWQ1fnvOc8yyWy+VyAABgh6653AMAAODqJigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAADJrss9AIAr1WsbZ+fYC5tzenM5+9YWc+j2tbl+3X+bAO+3WC6Xy8s9CIArxTPPnp5HHzszf/7D2pzZWJuZxbuOLmfv+ubcesfmPPrw3vnKF/ddrmECXFEEJcDMPP/i5tx3/1tz4uX9M4tzM8ttVgSdP37DLafm6JE9c+dta/+3cQJciayhBFbe4Uc25q6Du+fEK9dt/WK7mHzX8ROvXDd3Hdw9hx/Z+JhHCHBlM0MJrLR7Hzg5Tz95YGaW897H2x/W1nn3fPPkPPXEgY92cABXCTOUwMo6/MjG+Zic2VlMvnPe008emG9930wlsJrMUAIr6fkXN+eug7tnefaauXhMvjozj83Mr2fm+MzsnpkvzMxXZ+bwzLx77eRyFrvOzXN/fNuaSmDlCEpgJd34uVNbayYvul7ylzNz38zsmZmvz8znZ+btmTk2Mz+fmW/MzE/fe8ri3Nxw8xtz/KX9H8+gAa5QghJYOc88e3ru/tJ2n/z5x8zcOjM3zcxvZuaG9x3/22wF57cvfP3nTs+XD/mkELA6rKEEVs6jj53Z+vTPRT02M/+emSfmgzE5M/PZuVhMzuLc/OCHZ+oQAa4qZiiBlbN24M05s/Gpbf7iptl61P3qjq6/d/3N2Ty53fUBPlnMUAIr5cTJs+d3wLmYN2bmn7P18s3OnNlYm9c2zu74fICrjaAEVsrv/rQ5238i6I3z/3463GUxx17YDOcDXF0EJbBSTm9eapXP+d1y5l8f830APjkEJbBS9q1d6gPm183MjTPzl4/5PgCfHIISWCmHbl+bre0St3PPbL2Q8/sd3mV5/j4Aq0FQAivl+vVds3f9UusbH56ZfTPz4My8doHjr87Mjy969t71zbl+fdeOxwhwtRGUwMq59Y7NS3yH8jMz87OZ+fvM3Dwz35mZx2fmJzNz/8zcMjMvX/jUxbmt6wOsEN+hBFbOpXfK+a+/zsyP5p29vPfM1g46X5uZh87/fIHr2ykHWDGCElhJl97Lewfs5Q2sKI+8gZV09MieWVy7nEu/oPNhLWdx7XKOHrnwrCXAJ5mgBFbSnbetzYMPn5rtP3L+v1jMQ989NXfe5u1uYPV45A2stHsfODlPP3lgtmYqdxKXW+fd+8DG/OLx9Y92cABXCTOUwEp76okD89D3Nmax69wl3vy+gMW5Wew6N4cfEZPAajNDCTAzz7+4Offd/9aceHn/Vlhu97LO+eM33HJqjh7Z4zE3sPLMUALM1prK4y/tn1/99vQcvPv12bv+5nzwhZ3l7F1/cw7e/fo889zpOf7SfjEJMGYoAS7qtY2zc+yFzTm9uZx9a4s5dPuaHXAALkBQAgCQeOQNAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAImgBAAgEZQAACSCEgCARFACAJAISgAAEkEJAEAiKAEASAQlAACJoAQAIBGUAAAkghIAgERQAgCQCEoAABJBCQBAIigBAEgEJQAAiaAEACARlAAAJIISAIBEUAIAkAhKAAASQQkAQCIoAQBIBCUAAMl/ANuJL6zq4cuuAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7186, 0.2814])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7030, 0.2970])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST"
      ],
      "metadata": {
        "id": "iyczD_VhqLWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from Load_dataset import load_split_MUTAG_data, accuracy\n",
        "from Model import GCN\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "model_path = 'model/gcn_first.pth'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    adj_list, features_list, graph_labels, idx_map, idx_train, idx_val, idx_test = load_split_MUTAG_data()\n",
        "    model = GCN(nfeat=features_list[0].shape[1],  # nfeat = 7\n",
        "                nclass=graph_labels.max().item() + 1,  # nclass = 2\n",
        "                dropout=0.1)\n",
        "\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "    for i in idx_test:\n",
        "        output = model(features_list[i], adj_list[i])\n",
        "        output = output.unsqueeze(0)\n",
        "        outputs.append(output)\n",
        "    output = torch.cat(outputs, dim=0)\n",
        "\n",
        "    loss_test = F.cross_entropy(output, graph_labels[idx_test])\n",
        "    acc_test = accuracy(output, graph_labels[idx_test])\n",
        "    print(loss_test)\n",
        "    print(acc_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "6poe4hoUqMWr",
        "outputId": "815edafd-d8a1-46e8-df57-d8933edada84"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'Load_dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-11e0ad6d56c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mLoad_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_split_MUTAG_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Load_dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}